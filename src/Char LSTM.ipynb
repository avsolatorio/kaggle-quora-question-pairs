{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.hdf\n",
      "sample_submission.csv\n",
      "sample_submission.csv.zip\n",
      "test.csv\n",
      "test.csv.zip\n",
      "train.csv\n",
      "train.csv.zip\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from kaggle_quora_question_pairs_common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = load_train_test()\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 969 MB\n",
      "Current all-time max memory: 1214 MB\n",
      "Current all-time max memory: 1214 MB\n",
      "CPU times: user 1.14 s, sys: 84 ms, total: 1.22 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "include_test = False\n",
    "unique_questions = get_unique_questions(train_df, test_df, include_test=include_test)\n",
    "char_tfidf, word_tfidf = train_char_word_tfidf(unique_questions, include_test=include_test)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.77 s, sys: 100 ms, total: 5.87 s\n",
      "Wall time: 5.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "char_counts = Counter()\n",
    "\n",
    "for uq in unique_questions:\n",
    "    char_counts.update(uq)\n",
    "\n",
    "char_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char2id = {c: i + 1 for i, (c, _) in enumerate(char_counts.most_common())}\n",
    "char2id['UNK'] = 0\n",
    "id2char = {i: c for c, i in char2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_branch(input_layer):\n",
    "    x = input_layer  # keras.layers.Embedding(input_dim=len(char2id), output_dim=256, input_length=None)(input_layer)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(64))(x)\n",
    "#     x = keras.layers.LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    x = keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    return x\n",
    "\n",
    "input1 = keras.layers.Input(shape=(None, len(char2id)), name='input1')\n",
    "input2 = keras.layers.Input(shape=(None, len(char2id)), name='input2')\n",
    "input3 = keras.layers.Input(shape=(11,), name='input3')\n",
    "\n",
    "x1 = build_branch(input1)\n",
    "x2 = build_branch(input2)\n",
    "x3 = keras.layers.Dense(64, activation='tanh')(input3)\n",
    "x3 = keras.layers.Dropout(0.1)(x3)\n",
    "\n",
    "dot_layer = keras.layers.dot([x1, x2], axes=1, normalize=True)\n",
    "concat_layer = keras.layers.concatenate([x1, x2, x3, dot_layer])\n",
    "dense_layer = keras.layers.Dense(300, activation='relu')(concat_layer)\n",
    "dense_layer = keras.layers.Dropout(0.3)(dense_layer)\n",
    "output = keras.layers.Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "model = keras.models.Model(inputs=[input1, input2, input3], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metric=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(df, col, max_len=150):\n",
    "    x = np.zeros((df.shape[0], max_len, len(char2id)))\n",
    "    for ix, v in enumerate(df[col]):\n",
    "        for i, vv in enumerate(v):\n",
    "            if i < max_len:\n",
    "                x[ix][i][char2id[vv]] = 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = 50000\n",
    "# r1 = transform_data(train_df.head(N), 'question1')\n",
    "# r2 = transform_data(train_df.head(N), 'question2')\n",
    "# t = train_df.head(N).is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d = word_tfidf.transform(train_df.head(10))\n",
    "# d.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 12 ms, total: 148 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_tfidf_features(samp):\n",
    "#     w1 = word_tfidf.transform(samp.question1)\n",
    "#     w2 = word_tfidf.transform(samp.question2)\n",
    "\n",
    "    c1 = char_tfidf.transform(samp.question1)\n",
    "    c2 = char_tfidf.transform(samp.question2)\n",
    "\n",
    "    word_res = None\n",
    "#     word_res = np.dot(\n",
    "#         w1,\n",
    "#         w2.T\n",
    "#     ).diagonal()\n",
    "\n",
    "    char_res = np.dot(\n",
    "        c1,\n",
    "        c2.T\n",
    "    ).diagonal()\n",
    "\n",
    "    return word_res, char_res\n",
    "\n",
    "x = get_tfidf_features(train_df[10000: 11000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 1563 MB\n",
      "Current all-time max memory: 4751 MB\n"
     ]
    }
   ],
   "source": [
    "log_max_mem_usage()\n",
    "fasttext_model = fasttext.load_model('model_full_data.bin')\n",
    "log_max_mem_usage()\n",
    "\n",
    "stops = load_stopwords()\n",
    "num_pattern = re.compile('[0-9]+')\n",
    "math_pattern = re.compile('\\[math\\](.*)\\[\\/math\\]')\n",
    "\n",
    "nums = '01234567890'\n",
    "\n",
    "def transform_fasttext_vec(qs):\n",
    "    return np.array(\n",
    "        [fasttext_model[q.decode('utf-8')] for q in qs]\n",
    "    )\n",
    "\n",
    "_fs_cache = {}\n",
    "def cache_fasttext(j):\n",
    "    w = None\n",
    "    if j in _fs_cache:\n",
    "        w = _fs_cache[j]\n",
    "    else:\n",
    "        w = fasttext_model[j]\n",
    "        _fs_cache[j] = w\n",
    "    \n",
    "    return w\n",
    "    \n",
    "    \n",
    "def transform_fasttext_word_vec(qs, op='mean'):\n",
    "    qs_vec = []\n",
    "    for q in qs:\n",
    "        qd = []\n",
    "        q = q.decode('utf-8')\n",
    "        for j in q.split():\n",
    "            qd.append(cache_fasttext(j))\n",
    "        \n",
    "        if op == 'mean':\n",
    "            qs_vec.append(np.mean(qd, axis=0))\n",
    "        elif op == 'sum':\n",
    "            qs_vec.append(np.sum(qd, axis=0))\n",
    "        else:\n",
    "            raise ValueError('Unknown operation! Supported ops: [sum, mean].')\n",
    "    \n",
    "    return np.array(qs_vec)\n",
    "\n",
    "\n",
    "def get_fasttext_features(samp, is_fast=True):\n",
    "    fs_q1 = transform_fasttext_vec(samp.question1)\n",
    "    fs_q2 = transform_fasttext_vec(samp.question2)\n",
    "\n",
    "    fs_word_mean_q1 = transform_fasttext_word_vec(samp.question1, op='mean')\n",
    "    fs_word_mean_q2 = transform_fasttext_word_vec(samp.question2, op='mean')\n",
    "\n",
    "    if not is_fast:\n",
    "        fs_cos = cosine_similarity(fs_q1, fs_q2).diagonal()\n",
    "        fs_word_mean_cos = cosine_similarity(fs_word_mean_q1, fs_word_mean_q2).diagonal()    \n",
    "        fs_cos_q1_x_word_mean_q2_cos = cosine_similarity(fs_q1, fs_word_mean_q2).diagonal()\n",
    "        fs_cos_q2_x_word_mean_q1_cos = cosine_similarity(fs_word_mean_q1, fs_q2).diagonal()\n",
    "    \n",
    "    else:\n",
    "        fs_cos = fast_pairwise_cos_sim(fs_q1, fs_q2)\n",
    "        fs_word_mean_cos = fast_pairwise_cos_sim(fs_word_mean_q1, fs_word_mean_q2)\n",
    "        fs_cos_q1_x_word_mean_q2_cos = fast_pairwise_cos_sim(fs_q1, fs_word_mean_q2)\n",
    "        fs_cos_q2_x_word_mean_q1_cos = fast_pairwise_cos_sim(fs_word_mean_q1, fs_q2)\n",
    "\n",
    "    return fs_cos, fs_word_mean_cos, fs_cos_q1_x_word_mean_q2_cos, fs_cos_q2_x_word_mean_q1_cos\n",
    "\n",
    "\n",
    "def get_vector_based_features(data_df, local_batch=1000):\n",
    "    # data_df size should be about 40000 when used in parallel to observe effects of optimization.\n",
    "    i = 0\n",
    "\n",
    "#     word_dataset = np.array([])\n",
    "    char_dataset = np.array([])\n",
    "\n",
    "    fs_cos_dataset = np.array([])\n",
    "    fs_word_mean_cos_dataset = np.array([])\n",
    "    fs_cos_q1_x_word_mean_q2_cos_dataset = np.array([])\n",
    "    fs_cos_q2_x_word_mean_q1_cos_dataset = np.array([])\n",
    "\n",
    "    while True:\n",
    "        samp = data_df[i * local_batch: (i + 1) * local_batch]\n",
    "        i += 1\n",
    "\n",
    "        if samp.empty:\n",
    "            break\n",
    "            \n",
    "        word_res, char_res = get_tfidf_features(samp)\n",
    "        (\n",
    "            fs_cos, fs_word_mean_cos,\n",
    "            fs_cos_q1_x_word_mean_q2_cos, fs_cos_q2_x_word_mean_q1_cos\n",
    "        ) = get_fasttext_features(samp)\n",
    "\n",
    "#         word_dataset = np.concatenate([word_dataset, word_res])\n",
    "        char_dataset = np.concatenate([char_dataset, char_res])\n",
    "\n",
    "        fs_cos_dataset = np.concatenate([fs_cos_dataset, fs_cos])\n",
    "        fs_word_mean_cos_dataset = np.concatenate([fs_word_mean_cos_dataset, fs_word_mean_cos])\n",
    "        fs_cos_q1_x_word_mean_q2_cos_dataset = np.concatenate(\n",
    "            [fs_cos_q1_x_word_mean_q2_cos_dataset, fs_cos_q1_x_word_mean_q2_cos]\n",
    "        )\n",
    "        fs_cos_q2_x_word_mean_q1_cos_dataset = np.concatenate(\n",
    "            [fs_cos_q2_x_word_mean_q1_cos_dataset, fs_cos_q2_x_word_mean_q1_cos]\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "#             wv=word_dataset, \n",
    "            cv=char_dataset,\n",
    "            fs_cos=fs_cos_dataset,\n",
    "            fs_word_mean_cos=fs_word_mean_cos_dataset,\n",
    "            fs_cos_q1_x_word_mean_q2_cos=fs_cos_q1_x_word_mean_q2_cos_dataset,\n",
    "            fs_cos_q2_x_word_mean_q1_cos=fs_cos_q2_x_word_mean_q1_cos_dataset,\n",
    "        ), index=data_df.index\n",
    "    )\n",
    "\n",
    "def get_basic_features(df):\n",
    "    _df = pd.DataFrame()\n",
    "    _df['len_q1'] = df.question1.map(len)\n",
    "    _df['len_q2'] = df.question2.map(len)\n",
    "    _df['len_diff'] = (_df['len_q1'] - _df['len_q2']).abs()\n",
    "    \n",
    "    _df['num_terms_q1'] = df.question1.str.split().map(len)\n",
    "    _df['num_terms_q2'] = df.question2.str.split().map(len)\n",
    "    _df['num_terms_diff'] = (_df['num_terms_q1'] - _df['num_terms_q2']).abs()\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_based_score_parallel_interface(t_df, is_train):\n",
    "    return delayed(get_vector_based_features)(t_df)\n",
    "\n",
    "\n",
    "def parallel_scorer(samp, scorer_interface, is_train, batch, num_proc):\n",
    "    # Consumes 1.5G for batch=1000 and num_proc=4 for tfidf interface\n",
    "    # Use vector_based_features::batch=10000, heuristic_features::batch=20000\n",
    "    # scorer_interface::[heuristic_score_parallel_interface, vector_based_score_parallel_interface]\n",
    "    # Adjust batch depending on the interface used since the memory is dependent on the batch used.\n",
    "\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(scorer_interface(t_df, is_train))\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n",
    "\n",
    "\n",
    "def parallel_get_vector_based_scores(samp, is_train, batch=40000, num_proc=4):\n",
    "    # The batch size for the size of the dataset should be large to maximize effect of parallelization.\n",
    "    # The batch here is different from the batch used in the method `get_vector_based_features`\n",
    "    return parallel_scorer(samp, vector_based_score_parallel_interface, is_train, batch, num_proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch in main thread: 4000\n",
      "Current batch in main thread: 9000\n",
      "Current batch in main thread: 14000\n",
      "CPU times: user 104 ms, sys: 56 ms, total: 160 ms\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_based_features = parallel_get_vector_based_scores(train_df.head(10000), is_train=True, batch=1000, num_proc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 580 ms, sys: 16 ms, total: 596 ms\n",
      "Wall time: 595 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = get_vector_based_features(train_df.head(1000), local_batch=1000)\n",
    "# y = get_basic_features(train_df.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnmx_scaler = StandardScaler()\n",
    "y = get_basic_features(train_df.sample(n=100000))\n",
    "mnmx_scaler.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(df, batch_size, shuffle=True, is_train=True, other_feats=True):\n",
    "    while True:\n",
    "        for ix in xrange(0, (df.shape[0] + batch_size) // batch_size, batch_size):\n",
    "            vb = pd.DataFrame()\n",
    "            d = df[ix: ix + batch_size]\n",
    "            r1 = transform_data(d, 'question1')\n",
    "            r2 = transform_data(d, 'question2')\n",
    "            if other_feats:\n",
    "                basic_feats = get_basic_features(d)\n",
    "                bf_cols = basic_feats.columns\n",
    "                bf_inds = basic_feats.index\n",
    "                basic_feats = pd.DataFrame(mnmx_scaler.transform(basic_feats), columns=bf_cols, index=bf_inds)\n",
    "                \n",
    "                vector_feats = get_vector_based_features(d, local_batch=batch_size)\n",
    "                vb = pd.concat([basic_feats, vector_feats], axis=1)\n",
    "                        \n",
    "            res = [r1, r2]\n",
    "            \n",
    "            if is_train:\n",
    "                t = d.is_duplicate\n",
    "                yield (res + [vb] if not vb.empty else res, t)\n",
    "                yield (res[::-1] + [vb] if not vb.empty else res[::-1], t)\n",
    "            else:\n",
    "                yield res + [vb] if not vb.empty else res\n",
    "\n",
    "batch_size = 1000\n",
    "train_generator = data_generator(train_df, batch_size=batch_size, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# d = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "808/808 [==============================] - 647s - loss: 0.1076   \n",
      "Epoch 2/5\n",
      "808/808 [==============================] - 641s - loss: 0.0261   \n",
      "Epoch 3/5\n",
      "808/808 [==============================] - 641s - loss: 7.7961e-04   \n",
      "Epoch 4/5\n",
      "808/808 [==============================] - 641s - loss: 0.0057   \n",
      "Epoch 5/5\n",
      "808/808 [==============================] - 641s - loss: 9.4054e-05   \n",
      "CPU times: user 1h 24min 9s, sys: 8min 6s, total: 1h 32min 15s\n",
      "Wall time: 53min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c9e01fd50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator, steps_per_epoch=(train_df.shape[0] * 2) // batch_size, epochs=5, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173/1173 [==============================] - 1477s  \n",
      "CPU times: user 32min 28s, sys: 4min, total: 36min 29s\n",
      "Wall time: 24min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 2000\n",
    "test_generator = data_generator(test_df, batch_size=batch_size, is_train=False)\n",
    "preds = model.predict_generator(test_generator, steps=(test_df.shape[0] + batch_size) // batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "\n",
    "sub['test_id'] = test_df['test_id']\n",
    "sub['is_duplicate'] = preds[:test_df.shape[0]]\n",
    "\n",
    "sub.to_csv('deep_learning_submission_with_bidirectional_lstm_char_level_input_and_other_feats_{}.csv'.format(datetime.now()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id         1.173124e+06\n",
       "is_duplicate    2.795509e-01\n",
       "dtype: float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id         1.173124e+06\n",
       "is_duplicate    3.026665e-01\n",
       "dtype: float32"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id         1.173124e+06\n",
       "is_duplicate    2.987477e-01\n",
       "dtype: float32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.60815020e-16]\n",
      "[ 0.5662784]\n",
      "[  6.57736495e-12]\n",
      "[  5.27566371e-16]\n",
      "[ 0.13594559]\n",
      "[ 0.00520697]\n",
      "[ 0.99999928]\n",
      "[  4.59082194e-08]\n",
      "[ 0.96046102]\n",
      "[  3.14881774e-13]\n"
     ]
    }
   ],
   "source": [
    "for i in preds[:10]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.18356317e-02],\n",
       "       [  9.99907732e-01],\n",
       "       [  9.04752553e-01],\n",
       "       [  9.98574853e-01],\n",
       "       [  3.05210961e-38],\n",
       "       [  8.54544103e-01],\n",
       "       [  9.62314703e-38],\n",
       "       [  9.99891400e-01],\n",
       "       [  2.11539710e-08],\n",
       "       [  1.06082760e-01]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[90:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.270573e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.999444e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.999992e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.759588e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.021651e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.453658e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9.999400e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4.364194e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9.999988e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6.618966e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5.175192e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2.641608e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2.256322e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2.255567e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>9.999968e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>3.604797e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>9.999592e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>8.316178e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5.106286e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.200313e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>6.016943e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.747735e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>9.999785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.107928e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1.027331e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>4.030472e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>9.998782e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345766</th>\n",
       "      <td>2345766</td>\n",
       "      <td>1.534417e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345767</th>\n",
       "      <td>2345767</td>\n",
       "      <td>9.998739e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345768</th>\n",
       "      <td>2345768</td>\n",
       "      <td>3.434913e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345769</th>\n",
       "      <td>2345769</td>\n",
       "      <td>1.878331e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345770</th>\n",
       "      <td>2345770</td>\n",
       "      <td>1.405475e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345771</th>\n",
       "      <td>2345771</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345772</th>\n",
       "      <td>2345772</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345773</th>\n",
       "      <td>2345773</td>\n",
       "      <td>7.703352e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345774</th>\n",
       "      <td>2345774</td>\n",
       "      <td>4.971451e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345775</th>\n",
       "      <td>2345775</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345776</th>\n",
       "      <td>2345776</td>\n",
       "      <td>1.278241e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345777</th>\n",
       "      <td>2345777</td>\n",
       "      <td>7.870698e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345778</th>\n",
       "      <td>2345778</td>\n",
       "      <td>2.726665e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345779</th>\n",
       "      <td>2345779</td>\n",
       "      <td>3.726887e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345780</th>\n",
       "      <td>2345780</td>\n",
       "      <td>6.417799e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345781</th>\n",
       "      <td>2345781</td>\n",
       "      <td>2.057051e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345782</th>\n",
       "      <td>2345782</td>\n",
       "      <td>1.229493e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345783</th>\n",
       "      <td>2345783</td>\n",
       "      <td>4.259242e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345784</th>\n",
       "      <td>2345784</td>\n",
       "      <td>8.301694e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345785</th>\n",
       "      <td>2345785</td>\n",
       "      <td>1.836712e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345786</th>\n",
       "      <td>2345786</td>\n",
       "      <td>5.527684e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345787</th>\n",
       "      <td>2345787</td>\n",
       "      <td>6.297877e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345788</th>\n",
       "      <td>2345788</td>\n",
       "      <td>2.249318e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345789</th>\n",
       "      <td>2345789</td>\n",
       "      <td>1.950100e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345790</th>\n",
       "      <td>2345790</td>\n",
       "      <td>1.025383e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>7.004448e-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>9.999976e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>2.723178e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>1.386818e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>9.433615e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id  is_duplicate\n",
       "0              0  3.270573e-07\n",
       "1              1  9.999444e-01\n",
       "2              2  9.999992e-01\n",
       "3              3  2.759588e-19\n",
       "4              4  1.021651e-05\n",
       "5              5  5.453658e-01\n",
       "6              6  9.999400e-01\n",
       "7              7  4.364194e-13\n",
       "8              8  9.999988e-01\n",
       "9              9  6.618966e-05\n",
       "10            10  5.175192e-01\n",
       "11            11  2.641608e-34\n",
       "12            12  2.256322e-22\n",
       "13            13  2.255567e-20\n",
       "14            14  1.000000e+00\n",
       "15            15  9.999968e-01\n",
       "16            16  3.604797e-06\n",
       "17            17  1.000000e+00\n",
       "18            18  9.999592e-01\n",
       "19            19  8.316178e-10\n",
       "20            20  5.106286e-26\n",
       "21            21  1.200313e-12\n",
       "22            22  6.016943e-04\n",
       "23            23  1.747735e-12\n",
       "24            24  9.999785e-01\n",
       "25            25  1.107928e-10\n",
       "26            26  1.027331e-02\n",
       "27            27  4.030472e-10\n",
       "28            28  9.998782e-01\n",
       "29            29  0.000000e+00\n",
       "...          ...           ...\n",
       "2345766  2345766  1.534417e-11\n",
       "2345767  2345767  9.998739e-01\n",
       "2345768  2345768  3.434913e-26\n",
       "2345769  2345769  1.878331e-03\n",
       "2345770  2345770  1.405475e-12\n",
       "2345771  2345771  1.000000e+00\n",
       "2345772  2345772  1.000000e+00\n",
       "2345773  2345773  7.703352e-17\n",
       "2345774  2345774  4.971451e-27\n",
       "2345775  2345775  9.999999e-01\n",
       "2345776  2345776  1.278241e-04\n",
       "2345777  2345777  7.870698e-01\n",
       "2345778  2345778  2.726665e-13\n",
       "2345779  2345779  3.726887e-14\n",
       "2345780  2345780  6.417799e-12\n",
       "2345781  2345781  2.057051e-07\n",
       "2345782  2345782  1.229493e-11\n",
       "2345783  2345783  4.259242e-01\n",
       "2345784  2345784  8.301694e-10\n",
       "2345785  2345785  1.836712e-11\n",
       "2345786  2345786  5.527684e-10\n",
       "2345787  2345787  6.297877e-10\n",
       "2345788  2345788  2.249318e-22\n",
       "2345789  2345789  1.950100e-08\n",
       "2345790  2345790  1.025383e-03\n",
       "2345791  2345791  7.004448e-36\n",
       "2345792  2345792  9.999976e-01\n",
       "2345793  2345793  2.723178e-06\n",
       "2345794  2345794  1.386818e-28\n",
       "2345795  2345795  9.433615e-01\n",
       "\n",
       "[2345796 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.47786731e-05],\n",
       "       [  1.12011716e-04],\n",
       "       [  9.90686601e-15],\n",
       "       [  9.91899729e-01],\n",
       "       [  3.73673187e-21],\n",
       "       [  3.89634988e-05],\n",
       "       [  2.12161261e-11],\n",
       "       [  9.99967575e-01],\n",
       "       [  1.51059606e-26],\n",
       "       [  1.69954717e-10]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[90:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>Did my Adolf Hitler kill his dog Blondi to tes...</td>\n",
       "      <td>Did Trump land the DC post office project by f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>How will scrapping currency notes of INR 500 a...</td>\n",
       "      <td>What will happen to corruption money deposited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>What are exactly?</td>\n",
       "      <td>How does akamai great money?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>Who first masturbation experience?</td>\n",
       "      <td>What is your initial masturbation experience?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>I want may Amazon pay balance back to my bank ...</td>\n",
       "      <td>How do you perform top hat magic tricks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>What does it mean when my husband looks at oth...</td>\n",
       "      <td>What should I do when my husband looks for oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>For which exam a graduate electrical student s...</td>\n",
       "      <td>What are some criteria to be called ILLEGAL im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>How we can earn not easily?</td>\n",
       "      <td>How can I get genuine money easily?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>What are the to different symbols used by The ...</td>\n",
       "      <td>What does the nothing symbol mean ➰?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>What are which cannot be tamed by humans?</td>\n",
       "      <td>How did hal humans tame wild animals?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_id                                          question1  \\\n",
       "90       90  Did my Adolf Hitler kill his dog Blondi to tes...   \n",
       "91       91  How will scrapping currency notes of INR 500 a...   \n",
       "92       92                                  What are exactly?   \n",
       "93       93                 Who first masturbation experience?   \n",
       "94       94  I want may Amazon pay balance back to my bank ...   \n",
       "95       95  What does it mean when my husband looks at oth...   \n",
       "96       96  For which exam a graduate electrical student s...   \n",
       "97       97                        How we can earn not easily?   \n",
       "98       98  What are the to different symbols used by The ...   \n",
       "99       99          What are which cannot be tamed by humans?   \n",
       "\n",
       "                                            question2  \n",
       "90  Did Trump land the DC post office project by f...  \n",
       "91  What will happen to corruption money deposited...  \n",
       "92                       How does akamai great money?  \n",
       "93      What is your initial masturbation experience?  \n",
       "94           How do you perform top hat magic tricks?  \n",
       "95  What should I do when my husband looks for oth...  \n",
       "96  What are some criteria to be called ILLEGAL im...  \n",
       "97                How can I get genuine money easily?  \n",
       "98               What does the nothing symbol mean ➰?  \n",
       "99              How did hal humans tame wild animals?  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[90:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is it christians to create synthetic gold?'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[37].question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is give it possible to turn lead into gold?'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[37].question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
