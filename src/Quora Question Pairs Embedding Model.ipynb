{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.hdf\n",
      "sample_submission.csv\n",
      "sample_submission.csv.zip\n",
      "test.csv\n",
      "test.csv.zip\n",
      "train.csv\n",
      "train.csv.zip\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from kaggle_quora_question_pairs_common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.94 s, sys: 208 ms, total: 6.15 s\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, test_df = load_train_test()\n",
    "unique_questions = get_unique_questions(train_df, test_df, include_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_sentences = unique_questions[:100000].str.replace('?', '').replace('.', '').str.replace('\\W', ' ').str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def train_word2vec(\n",
    "#     tokenized_questions,\n",
    "#     pre_trained_model='GoogleNews-vectors-negative300.bin.gz'\n",
    "#     size=300,\n",
    "#     iter=100,\n",
    "#     min_count=1,\n",
    "#     negative=10,\n",
    "#     workers=7,\n",
    "#     min_alpha=0.0001,\n",
    "#     window=5\n",
    "# ):\n",
    "#     # https://github.com/RaRe-Technologies/gensim/issues/1245\n",
    "#     # List of tokenized questions.\n",
    "#     # e.g. ['What', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india']\n",
    "#     # pre_trained_model can be any pre trained model that gensim accepts, e.g., Glove or GoogleNews word2vec\n",
    "\n",
    "#     # Initialize model\n",
    "#     word_vectors = Word2Vec(\n",
    "#         size=size, iter=iter, min_count=min_count, negative=negative, workers=workers,\n",
    "#         min_alpha=min_alpha, window=window,\n",
    "#     )\n",
    "\n",
    "#     # Initialize vocab\n",
    "#     word_vectors.build_vocab(my_sentences)\n",
    "\n",
    "#     # Initialize vectors in local model with with vectors from pre-trained model with overlapping vocabulary.\n",
    "#     # Set `lockf` to 1 for re-training\n",
    "#     word_vectors.intersect_word2vec_format(pre_trained_model, lockf=1, binary=True)\n",
    "\n",
    "#     # Adjust pre-trained vectors to adapt its distribution with that of the local data via retraining.\n",
    "#     word_vectors.train(tokenized_questions)\n",
    "\n",
    "#     return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 20s, sys: 9.57 s, total: 12min 30s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_vectors = train_word2vec(my_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3287                                    []\n",
       "3288    [How, do, you, trace, your, roots]\n",
       "dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentences[3287:3289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 300)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.array([word_vectors[i] for i in st]).mean(axis=0) if st else np.zeros(300) for st in my_sentences[3285:3290]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 628 ms, sys: 12 ms, total: 640 ms\n",
      "Wall time: 640 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_dist = einsum_pairwise_cos_sim(\n",
    "    np.array([np.array([word_vectors[i] for i in st]).mean(axis=0) if st else np.random.randn(300) for st in my_sentences[:10000]]),\n",
    "    np.array([np.array([word_vectors[i] for i in st]).mean(axis=0) if st else np.random.randn(300) for st in my_sentences[10000:20000]]),\n",
    "#     binary_input=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'buxar' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-ac50a5148929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'buxar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/avsolatorio/anaconda/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avsolatorio/anaconda/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avsolatorio/anaconda/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'buxar' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "word_vectors.most_similar('buxar', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Noor', 0.4805505871772766),\n",
       " ('Meghnath', 0.4656824469566345),\n",
       " ('Koh', 0.44670557975769043),\n",
       " ('Jaya', 0.4466068148612976),\n",
       " ('Kingsley', 0.44049006700515747),\n",
       " ('Chhotepur', 0.4382625222206116),\n",
       " ('dhampir', 0.433312326669693),\n",
       " ('Mumtaz', 0.4214532971382141),\n",
       " ('Mormont', 0.41787993907928467),\n",
       " ('rani', 0.41724181175231934),\n",
       " ('Mughal', 0.41038641333580017),\n",
       " ('Divya', 0.40834560990333557),\n",
       " ('Aadam', 0.4072263836860657),\n",
       " ('Nagarjun', 0.40593525767326355),\n",
       " ('Kunti', 0.4028519093990326),\n",
       " ('Anaximander', 0.3990257680416107),\n",
       " ('sanyogita', 0.39638152718544006),\n",
       " ('Warframe', 0.396377831697464),\n",
       " ('Biswa', 0.3936367630958557),\n",
       " ('Maharana', 0.39177757501602173)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('Kohinoor', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sigmoid', 0.3332473337650299),\n",
       " ('oberving', 0.32975703477859497),\n",
       " ('ramp', 0.3224278390407562),\n",
       " ('prevoius', 0.314231276512146),\n",
       " ('HDDs', 0.2744296193122864),\n",
       " ('cassandra', 0.273955762386322),\n",
       " ('encouraging', 0.2650046944618225),\n",
       " ('oneself', 0.2644054889678955),\n",
       " ('standardised', 0.260725200176239),\n",
       " ('Remicade', 0.2591109275817871),\n",
       " ('nullification', 0.25816383957862854),\n",
       " ('Jaylah', 0.25565558671951294),\n",
       " ('Goenkaji', 0.25030404329299927),\n",
       " ('councelling', 0.24795880913734436),\n",
       " ('algebra', 0.2456909567117691),\n",
       " ('steps', 0.2454134076833725),\n",
       " ('deciding', 0.2434847205877304),\n",
       " ('Wan', 0.24254292249679565),\n",
       " ('mainsAs', 0.24145886301994324),\n",
       " ('sitting', 0.2404625564813614)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('step', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arnd', 0.45440879464149475),\n",
       " ('rnkd', 0.4270583689212799),\n",
       " ('europe', 0.3883877098560333),\n",
       " ('Shud', 0.35802578926086426),\n",
       " ('canada', 0.3521583080291748),\n",
       " ('maidsin', 0.34342166781425476),\n",
       " ('melbourne', 0.3340461552143097),\n",
       " ('vit', 0.33228057622909546),\n",
       " ('nz', 0.32583385705947876),\n",
       " ('MedSchool', 0.3206053376197815),\n",
       " ('switzerland', 0.3175039291381836),\n",
       " ('rohini', 0.3133656978607178),\n",
       " ('Sinai', 0.3110540509223938),\n",
       " ('Canada', 0.30992138385772705),\n",
       " ('J2', 0.3089248538017273),\n",
       " ('saudi', 0.30678361654281616),\n",
       " ('ca', 0.3023535907268524),\n",
       " ('london', 0.30002766847610474),\n",
       " ('spain', 0.29272031784057617),\n",
       " ('nasa', 0.2923283576965332)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('usa', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31756443408502433"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity('mail', 'email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5volts', 0.4091402292251587),\n",
       " ('21volts', 0.40539640188217163),\n",
       " ('255', 0.40468814969062805),\n",
       " ('254', 0.38108837604522705),\n",
       " ('th8', 0.37641918659210205),\n",
       " ('KMs', 0.36274099349975586),\n",
       " ('Determine', 0.32687830924987793),\n",
       " ('th10', 0.3185482621192932),\n",
       " ('7x', 0.3072971999645233),\n",
       " ('horizontal', 0.3067953884601593)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kingsley', 0.4966827630996704),\n",
       " ('dhampir', 0.48333466053009033),\n",
       " ('Koh', 0.4614385962486267),\n",
       " ('Meghnath', 0.444887638092041),\n",
       " ('victorian', 0.4388747215270996),\n",
       " ('Sant', 0.434789776802063),\n",
       " ('Noor', 0.4341884255409241),\n",
       " ('APJ', 0.4285680651664734),\n",
       " ('Babar', 0.4280354976654053),\n",
       " ('Gus', 0.42005109786987305)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('Kohinoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USPS', 0.4655623137950897),\n",
       " ('mailbox', 0.4029355049133301),\n",
       " ('fax', 0.37872570753097534),\n",
       " ('FedEx', 0.3612022399902344),\n",
       " ('mailman', 0.3605952858924866),\n",
       " ('delivers', 0.3511347472667694),\n",
       " ('Parcel', 0.34227150678634644),\n",
       " ('transcript', 0.3388373553752899),\n",
       " ('Flipkart', 0.3243950605392456),\n",
       " ('mailed', 0.32292044162750244)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mumbai', 0.3737698793411255),\n",
       " ('subcontinent', 0.37103790044784546),\n",
       " ('Nepal', 0.3696967661380768),\n",
       " ('Pakistan', 0.3648681044578552),\n",
       " ('Indian', 0.3556423783302307),\n",
       " ('time', 0.34662944078445435),\n",
       " ('Bangalore', 0.33646100759506226),\n",
       " ('Kerala', 0.32918962836265564),\n",
       " ('in', 0.31129133701324463),\n",
       " ('Goa', 0.3068421483039856)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 0.3641197085380554),\n",
       " ('Mumbai', 0.33095571398735046),\n",
       " ('Psychology', 0.3292388916015625),\n",
       " ('Australia', 0.32473915815353394),\n",
       " ('Infosys', 0.320180207490921),\n",
       " ('Chandigarh', 0.3180716633796692),\n",
       " ('IPC', 0.31621208786964417),\n",
       " ('Greece', 0.30715009570121765),\n",
       " ('Nepal', 0.30185842514038086),\n",
       " ('Kerala', 0.2966611087322235)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input_file     training file path (required)\n",
    "# output         output file path (required)\n",
    "# lr             learning rate [0.05]\n",
    "# lr_update_rate change the rate of updates for the learning rate [100]\n",
    "# dim            size of word vectors [100]\n",
    "# ws             size of the context window [5]\n",
    "# epoch          number of epochs [5]\n",
    "# min_count      minimal number of word occurences [5]\n",
    "# neg            number of negatives sampled [5]\n",
    "# word_ngrams    max length of word ngram [1]\n",
    "# loss           loss function {ns, hs, softmax} [ns]\n",
    "# bucket         number of buckets [2000000]\n",
    "# minn           min length of char ngram [3]\n",
    "# maxn           max length of char ngram [6]\n",
    "# thread         number of threads [12]\n",
    "# t              sampling threshold [0.0001]\n",
    "# silent         disable the log output from the C++ extension [1]\n",
    "# encoding       specify input_file encoding [utf-8]\n",
    "\n",
    "# Includes test data in unique_questions\n",
    "# pd.Series(unique_questions[:100000]).to_csv('questions_data_1000.csv', index=False)\n",
    "# NUM_PROC = 7\n",
    "# model = fasttext.skipgram('questions_data.csv', 'model_full_data', dim=300, epoch=30, thread=NUM_PROC, word_ngrams=2)\n",
    "# print model.words # list of words in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 136 MB\n",
      "Current all-time max memory: 3345 MB\n"
     ]
    }
   ],
   "source": [
    "log_max_mem_usage()\n",
    "model = fasttext.load_model('model_full_data.bin')\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78911119]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model[\"she is so India\"], model[\"she's so India\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56863613]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"she's so beautiful\"\n",
    "s2 = \"she is pretty\"\n",
    "cosine_similarity(\n",
    "    np.sum([model[i] for i in s1.split()], axis=0),\n",
    "    np.sum([model[i] for i in s2.split()], axis=0),\n",
    "#     model[\"she's so beautiful\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04152137041091919,\n",
       " 0.13310760259628296,\n",
       " -0.10164530575275421,\n",
       " -0.30697593092918396,\n",
       " -0.17883634567260742,\n",
       " -0.20952075719833374,\n",
       " -0.0179507564753294,\n",
       " -0.125959575176239,\n",
       " 0.14448928833007812,\n",
       " 0.08694171905517578,\n",
       " -0.10691135376691818,\n",
       " 0.007618176285177469,\n",
       " -0.29107901453971863,\n",
       " 0.09584323316812515,\n",
       " -0.12915417551994324,\n",
       " 0.06449639052152634,\n",
       " -0.020849671214818954,\n",
       " 0.32004767656326294,\n",
       " 0.26843661069869995,\n",
       " 0.025120973587036133,\n",
       " 0.1991555243730545,\n",
       " 0.056532133370637894,\n",
       " 0.03374658524990082,\n",
       " -0.11863112449645996,\n",
       " 0.4082769453525543,\n",
       " -0.010660517029464245,\n",
       " 0.3905940651893616,\n",
       " -0.3011779487133026,\n",
       " 0.13229729235172272,\n",
       " -0.041249096393585205,\n",
       " 0.03876839950680733,\n",
       " -0.04387875646352768,\n",
       " -0.04876932501792908,\n",
       " 0.0779765248298645,\n",
       " -0.3986589312553406,\n",
       " 0.03987919166684151,\n",
       " -0.11276043206453323,\n",
       " -0.05412406101822853,\n",
       " 0.13856494426727295,\n",
       " -0.03304140642285347,\n",
       " 0.0007616299553774297,\n",
       " 0.164107084274292,\n",
       " -0.2787626087665558,\n",
       " -0.1146128699183464,\n",
       " -0.04397188499569893,\n",
       " -0.1647150218486786,\n",
       " -0.16029894351959229,\n",
       " -0.06425792723894119,\n",
       " 0.0325561948120594,\n",
       " -0.24516917765140533,\n",
       " -0.034332867711782455,\n",
       " -0.006776446010917425,\n",
       " 0.12071248143911362,\n",
       " 0.1441788524389267,\n",
       " 0.17827652394771576,\n",
       " -0.15842947363853455,\n",
       " -0.04418424889445305,\n",
       " -0.04663139581680298,\n",
       " 0.38144272565841675,\n",
       " -0.12106972187757492,\n",
       " 0.045027460902929306,\n",
       " 0.024987587705254555,\n",
       " 0.04055391997098923,\n",
       " -0.10166583210229874,\n",
       " -0.2767518162727356,\n",
       " 0.10324139147996902,\n",
       " -0.06062135845422745,\n",
       " 0.13220873475074768,\n",
       " 0.2628428041934967,\n",
       " -0.07437040656805038,\n",
       " -0.19675840437412262,\n",
       " -0.05178966745734215,\n",
       " 0.22948460280895233,\n",
       " -0.03366951644420624,\n",
       " -0.020196428522467613,\n",
       " 0.023070838302373886,\n",
       " 0.2427472323179245,\n",
       " 0.28731241822242737,\n",
       " 0.20999988913536072,\n",
       " 0.04020730033516884,\n",
       " -0.07830813527107239,\n",
       " 0.10162917524576187,\n",
       " -0.05544978752732277,\n",
       " -0.1746641844511032,\n",
       " 0.08416389673948288,\n",
       " 0.046910360455513,\n",
       " 0.1636420041322708,\n",
       " 0.09059732407331467,\n",
       " 0.09224867820739746,\n",
       " -0.1664249449968338,\n",
       " 0.0028367971535772085,\n",
       " 0.0768810287117958,\n",
       " -0.040087781846523285,\n",
       " 0.2077704668045044,\n",
       " 0.026887403801083565,\n",
       " -0.08921728283166885,\n",
       " 0.02289118617773056,\n",
       " 0.11272106319665909,\n",
       " 0.1837129145860672,\n",
       " 0.16819146275520325,\n",
       " 0.2966860234737396,\n",
       " 0.18686901032924652,\n",
       " 0.05342232808470726,\n",
       " -0.22383509576320648,\n",
       " 0.04645839333534241,\n",
       " 0.01772790215909481,\n",
       " -0.01670943759381771,\n",
       " 0.244553804397583,\n",
       " 0.036902572959661484,\n",
       " -0.12027868628501892,\n",
       " 0.22170528769493103,\n",
       " -0.06658124178647995,\n",
       " 0.16139176487922668,\n",
       " -0.10138116031885147,\n",
       " 0.10189157724380493,\n",
       " -0.008884722366929054,\n",
       " 0.19628757238388062,\n",
       " -0.2771637737751007,\n",
       " -0.13979710638523102,\n",
       " -0.15262509882450104,\n",
       " -0.004391546361148357,\n",
       " 0.05528416112065315,\n",
       " 0.044389549642801285,\n",
       " 0.29034513235092163,\n",
       " -0.008716123178601265,\n",
       " -0.227649986743927,\n",
       " 0.011358152143657207,\n",
       " -0.133702352643013,\n",
       " -0.011981901712715626,\n",
       " 0.18855056166648865,\n",
       " -0.04184447601437569,\n",
       " -0.0814095288515091,\n",
       " -0.15173718333244324,\n",
       " -0.31114885210990906,\n",
       " 0.005038671661168337,\n",
       " 0.010532599873840809,\n",
       " 0.048545874655246735,\n",
       " -0.0837041512131691,\n",
       " -0.0057991258800029755,\n",
       " 0.12117713689804077,\n",
       " -0.23157423734664917,\n",
       " 0.007692879997193813,\n",
       " 0.2894243597984314,\n",
       " -0.09816811233758926,\n",
       " -0.15384621918201447,\n",
       " -0.014738879166543484,\n",
       " -0.2528254985809326,\n",
       " 0.06621045619249344,\n",
       " -0.05827062949538231,\n",
       " -0.037000544369220734,\n",
       " 0.11068044602870941,\n",
       " -0.2975730895996094,\n",
       " -0.3634035289287567,\n",
       " 0.029428740963339806,\n",
       " 0.06173213571310043,\n",
       " 0.058803774416446686,\n",
       " -0.06284349411725998,\n",
       " 0.2851720452308655,\n",
       " -0.14799681305885315,\n",
       " 0.0799645259976387,\n",
       " -0.13628727197647095,\n",
       " 0.11036384850740433,\n",
       " -0.06297066062688828,\n",
       " 0.08580594509840012,\n",
       " 0.1561630368232727,\n",
       " -0.23021090030670166,\n",
       " 0.15541066229343414,\n",
       " -0.14923341572284698,\n",
       " 0.00626535527408123,\n",
       " -0.19850198924541473,\n",
       " -0.25738707184791565,\n",
       " 0.10907932370901108,\n",
       " -0.19035889208316803,\n",
       " -0.33923622965812683,\n",
       " 0.12259548902511597,\n",
       " -0.3124716281890869,\n",
       " 0.09752734750509262,\n",
       " -0.26197826862335205,\n",
       " 0.11504840105772018,\n",
       " -0.14502933621406555,\n",
       " -0.29404544830322266,\n",
       " 0.031094204634428024,\n",
       " -0.06029685586690903,\n",
       " -0.05633867532014847,\n",
       " -0.3159458041191101,\n",
       " 0.08910173922777176,\n",
       " 0.13092604279518127,\n",
       " -0.04601173475384712,\n",
       " -0.06220481917262077,\n",
       " 0.24800850450992584,\n",
       " -0.05001619830727577,\n",
       " -0.10958315432071686,\n",
       " 0.012083841487765312,\n",
       " -0.030336735770106316,\n",
       " 0.2583954334259033,\n",
       " -0.19176089763641357,\n",
       " 0.022891808301210403,\n",
       " 0.15011245012283325,\n",
       " -0.1671098917722702,\n",
       " -0.12968887388706207,\n",
       " -0.09514806419610977,\n",
       " 0.4234541952610016,\n",
       " 0.05186633765697479,\n",
       " -0.044539809226989746,\n",
       " -0.04298039525747299,\n",
       " 0.1483880579471588,\n",
       " -0.04099268093705177,\n",
       " -0.1580384373664856,\n",
       " -0.00348620000295341,\n",
       " 0.17912013828754425,\n",
       " 0.03633078560233116,\n",
       " 0.13543730974197388,\n",
       " -0.03553898259997368,\n",
       " 0.028532231226563454,\n",
       " -0.2599625885486603,\n",
       " 0.07144688069820404,\n",
       " 0.4047987759113312,\n",
       " 0.10060004144906998,\n",
       " 0.2223103940486908,\n",
       " -0.032644979655742645,\n",
       " -0.057889919728040695,\n",
       " -0.1351940631866455,\n",
       " 0.31381797790527344,\n",
       " 0.04172350466251373,\n",
       " -0.1646510511636734,\n",
       " 0.1920679211616516,\n",
       " -0.007071377709507942,\n",
       " 0.08080483227968216,\n",
       " 0.10573934018611908,\n",
       " -0.022931598126888275,\n",
       " 0.04590291529893875,\n",
       " -0.043025121092796326,\n",
       " -0.10491251200437546,\n",
       " -0.2446850687265396,\n",
       " -0.002809182507917285,\n",
       " 0.056475911289453506,\n",
       " -0.04286873713135719,\n",
       " -0.28699326515197754,\n",
       " 0.10358869284391403,\n",
       " -0.30414098501205444,\n",
       " -0.1896825134754181,\n",
       " 0.09942317008972168,\n",
       " 0.34935519099235535,\n",
       " 0.08350516110658646,\n",
       " 0.13336984813213348,\n",
       " -0.11877121776342392,\n",
       " -0.11424984037876129,\n",
       " -0.37190568447113037,\n",
       " -0.187744140625,\n",
       " 0.030618444085121155,\n",
       " -0.21908052265644073,\n",
       " 0.023003429174423218,\n",
       " 0.04534867778420448,\n",
       " 0.11334088444709778,\n",
       " -0.11618021130561829,\n",
       " 0.06062743440270424,\n",
       " 0.10677573829889297,\n",
       " -0.1965702623128891,\n",
       " -0.18606267869472504,\n",
       " -0.13762266933918,\n",
       " -0.11941293627023697,\n",
       " 0.25159138441085815,\n",
       " 0.00490431347861886,\n",
       " 0.1216912567615509,\n",
       " 0.6385194063186646,\n",
       " -0.017616458237171173,\n",
       " 0.09576798230409622,\n",
       " 0.12321005761623383,\n",
       " 0.12410271167755127,\n",
       " -0.047809209674596786,\n",
       " -0.2707660496234894,\n",
       " 0.09593599289655685,\n",
       " -0.057347558438777924,\n",
       " -0.2972469925880432,\n",
       " -0.02425653487443924,\n",
       " -0.1415639966726303,\n",
       " 0.3524526059627533,\n",
       " -0.11881836503744125,\n",
       " 0.10722173005342484,\n",
       " -0.28168219327926636,\n",
       " -0.11504816263914108,\n",
       " 0.11122845113277435,\n",
       " -0.17811237275600433,\n",
       " 0.12407905608415604,\n",
       " 0.32549619674682617,\n",
       " -0.006649257615208626,\n",
       " 0.23427429795265198,\n",
       " 0.014792843721807003,\n",
       " -0.07339583337306976,\n",
       " -0.07130017131567001,\n",
       " 0.11833536624908447,\n",
       " 0.3316795825958252,\n",
       " 0.21569590270519257,\n",
       " -0.35394275188446045,\n",
       " 0.0896148756146431,\n",
       " 0.02548213116824627,\n",
       " 0.18571265041828156,\n",
       " -0.016951899975538254,\n",
       " 0.1380382478237152,\n",
       " 0.0596979521214962]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Consumes 6G when loaded\n",
    "wvmodel = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.515625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(wvmodel.vocab) * 300 * 4.) / (1024 * 1000 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wvmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f59018843388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwvmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wvmodel' is not defined"
     ]
    }
   ],
   "source": [
    "wvmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
