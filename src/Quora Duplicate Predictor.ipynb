{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.hdf\n",
      "sample_submission.csv\n",
      "sample_submission.csv.zip\n",
      "test.csv\n",
      "test.csv.zip\n",
      "train.csv\n",
      "train.csv.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import resource\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# ------- Define modular methods for the task\n",
    "def log_max_mem_usage():\n",
    "    print(\n",
    "        \"Current all-time max memory: {} MB\".format(\n",
    "            resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df.fillna('zxzxzx zxzxzx', inplace=True) # For id: qid2 174364\n",
    "\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "test_df.fillna('zxzxzx zxzxzx', inplace=True)\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 798 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_max_mem_usage()\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 15.8 s, total: 31.4 s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset_store = pd.HDFStore('../input/dataset.hdf', mode='w')\n",
    "dataset_store.append('train_df', train_df)\n",
    "dataset_store.append('test_df', test_df)\n",
    "dataset_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  qid1  qid2                                          question1  \\\n",
      "10  10    21    22  Method to find separation of slits using fresn...   \n",
      "11  11    23    24        How do I read and find my YouTube comments?   \n",
      "12  12    25    26               What can make Physics easy to learn?   \n",
      "13  13    27    28        What was your first sexual experience like?   \n",
      "14  14    29    30  What are the laws to change your status from a...   \n",
      "15  15    31    32  What would a Trump presidency mean for current...   \n",
      "16  16    33    34                       What does manipulation mean?   \n",
      "17  17    35    36  Why do girls want to be friends with the guy t...   \n",
      "18  18    37    38  Why are so many Quora users posting questions ...   \n",
      "19  19    39    40  Which is the best digital marketing institutio...   \n",
      "\n",
      "                                            question2  is_duplicate  \n",
      "10  What are some of the things technicians can te...             0  \n",
      "11             How can I see all my Youtube comments?             1  \n",
      "12            How can you make physics easy to learn?             1  \n",
      "13             What was your first sexual experience?             1  \n",
      "14  What are the laws to change your status from a...             0  \n",
      "15  How will a Trump presidency affect the student...             1  \n",
      "16                      What does manipulation means?             1  \n",
      "17           How do guys feel after rejecting a girl?             0  \n",
      "18  Why do people ask Quora questions which can be...             1  \n",
      "19  Which is the best digital marketing institute ...             0  \n",
      "CPU times: user 44 ms, sys: 8 ms, total: 52 ms\n",
      "Wall time: 45.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "dd = dataset_store.select('train_df', where=train_df.index[10:20])\n",
    "dataset_store.close()\n",
    "print dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# def score_heuristic_batch(samp_index):\n",
    "#     dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "#     samp = dataset_store.select('train_df', where=samp_index)\n",
    "#     dataset_store.close()\n",
    "\n",
    "#     heuristics_scores = []\n",
    "\n",
    "#     for row in samp.iterrows():\n",
    "# #         if row[0] and row[0] % 10000 == 0:\n",
    "# #             print(row[0])\n",
    "#         heuristics_scores.append(score_row(row))\n",
    "\n",
    "#     heuristics_scores = pd.DataFrame(heuristics_scores, index=samp.index)\n",
    "\n",
    "#     return heuristics_scores\n",
    "\n",
    "\n",
    "# def heuristic_score_parallel_interface(t_df):\n",
    "#     return delayed(score_heuristic_batch)(t_df.index)\n",
    "\n",
    "\n",
    "# def tfidf_score_parallel_interface(t_df):\n",
    "#     return delayed(get_tfidf_features)(t_df)\n",
    "\n",
    "\n",
    "# def parallel_scorer(samp, scorer_interface, batch, num_proc):\n",
    "#     # Consumes 1.5G for batch=1000 and num_proc=4 for tfidf interface\n",
    "#     # Use tfidf_features::batch=1000, heuristic_features::batch=20000\n",
    "#     # scorer_interface::[heuristic_score_parallel_interface, tfidf_score_parallel_interface]\n",
    "#     # Adjust batch depending on the interface used since the memory is dependent on the batch used.\n",
    "\n",
    "#     with Parallel(n_jobs=num_proc) as parallel:\n",
    "#         dataset = []\n",
    "#         is_break = False\n",
    "#         i = 0\n",
    "\n",
    "#         while not is_break:\n",
    "#             payload = []\n",
    "\n",
    "#             for j in xrange(num_proc):\n",
    "#                 t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "#                 if t_df.empty:\n",
    "#                     is_break = True\n",
    "#                     continue\n",
    "\n",
    "#                 payload.append(scorer_interface(t_df))\n",
    "#             print((i + j) * batch)\n",
    "\n",
    "#             if payload:\n",
    "#                 results = parallel(payload)\n",
    "#                 dataset.extend(results)\n",
    "#                 i += num_proc\n",
    "\n",
    "#     return pd.concat(dataset)\n",
    "\n",
    "\n",
    "# def parallel_get_heuristic_scores(samp, batch=10000, num_proc=4):\n",
    "#     return parallel_scorer(samp, heuristic_score_parallel_interface, batch, num_proc)\n",
    "\n",
    "\n",
    "# def parallel_get_tfidf_scores(samp, batch=1000, num_proc=4):\n",
    "#     return parallel_scorer(samp, tfidf_score_parallel_interface, batch, num_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# d = parallel_get_heuristic_scores(train_df.head(200000), batch=10000, num_proc=4)\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 798 MB\n"
     ]
    }
   ],
   "source": [
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 2115 MB\n",
      "CPU times: user 55.3 s, sys: 564 ms, total: 55.9 s\n",
      "Wall time: 55.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "unique_questions = pd.Series(pd.concat([train_df.question1, train_df.question2]).unique())\n",
    "# combined_featurizers.fit(unique_questions)\n",
    "\n",
    "char_tfidf = TfidfVectorizer(analyzer='char', ngram_range=(2, 3))  # featurizers[0][1]\n",
    "word_tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))  # featurizers[1][1]\n",
    "char_tfidf.fit(unique_questions)\n",
    "word_tfidf.fit(unique_questions)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# d = get_tfidf_features(train_df[:100000], batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "num_pattern = re.compile('[0-9]+')\n",
    "math_pattern = re.compile('\\[math\\](.*)\\[\\/math\\]')\n",
    "\n",
    "nums = '01234567890'\n",
    "\n",
    "\n",
    "def get_tfidf_features(data_df, batch=1000):\n",
    "    # data_df size should be about 40000 when used in parallel to observe effects of optimization.\n",
    "    i = 0\n",
    "#     print('Current data size in `get_tfidf_features`: {}'.format(data_df.shape[0]))\n",
    "\n",
    "    word_dataset = np.array([])\n",
    "    char_dataset = np.array([])\n",
    "\n",
    "    while True:\n",
    "        samp = data_df[i * batch: (i + 1) * batch]\n",
    "        i += 1\n",
    "#         print_batch = i * batch % 10000\n",
    "\n",
    "#         if print_batch == 0:\n",
    "#             print('Batch process in `get_tfidf_features`: {}'.format(i * batch))\n",
    "\n",
    "        if samp.empty:\n",
    "            break\n",
    "\n",
    "        word_res = np.dot(\n",
    "            word_tfidf.transform(samp.question1),\n",
    "            word_tfidf.transform(samp.question2).T\n",
    "        ).diagonal()\n",
    "        \n",
    "        char_res = np.dot(\n",
    "            char_tfidf.transform(samp.question1),\n",
    "            char_tfidf.transform(samp.question2).T\n",
    "        ).diagonal()\n",
    "\n",
    "        word_dataset = np.concatenate([word_dataset, word_res])\n",
    "        char_dataset = np.concatenate([char_dataset, char_res])\n",
    "\n",
    "    return pd.DataFrame(dict(wv=word_dataset, cv=char_dataset), index=data_df.index)\n",
    "\n",
    "\n",
    "def get_heuristic_scores(q1, q2, ns_q1, ns_q2, swap):\n",
    "#     n_q1 = {}\n",
    "#     n_q2 = {}\n",
    "\n",
    "#     for n in nums:\n",
    "#         qc1 = q1.count(n)\n",
    "#         qc2 = q2.count(n)\n",
    "#         n_q1['q1_{}'.format(n)] = qc1\n",
    "#         n_q2['q2_{}'.format(n)] = qc2\n",
    "\n",
    "    if swap:\n",
    "        q1 = ns_q1\n",
    "        q2 = ns_q2\n",
    "\n",
    "    exact_nums_q1 = num_pattern.findall(q1)\n",
    "    exact_nums_q2 = num_pattern.findall(q2)\n",
    "    \n",
    "    math_q1 = math_pattern.findall(q1)\n",
    "    math_q2 = math_pattern.findall(q2)\n",
    "\n",
    "    num_exact_nums_match = len([n1 for n1 in exact_nums_q1 if n1 in exact_nums_q2])\n",
    "    math_pattern_match = len([n1 for n1 in math_q1 if n1 in math_q2])\n",
    "    \n",
    "    is_q1_math = 1 * any(math_q1)\n",
    "    is_q2_math = 1 * any(math_q2)\n",
    "    is_both_math = is_q1_math * is_q2_math\n",
    "\n",
    "#     qq2 = pd.Series(Counter([s for s in q1 if s.isupper()]))\n",
    "#     qq1 = pd.Series(Counter([s for s in q2 if s.isupper()]))\n",
    "    \n",
    "#     sim_caps_rate = (qq1/qq2).mean()\n",
    "#     num_caps_q1 = qq1.sum() \n",
    "#     num_caps_q2 = qq2.sum()\n",
    "\n",
    "#     mean_caps_q1 = qq1.mean() \n",
    "#     mean_caps_q2 = qq2.mean()\n",
    "    \n",
    "    num_terms_q1 = len(q1.split())\n",
    "    num_terms_q2 = len(q2.split())\n",
    "    \n",
    "    len_q1 = len(q1)\n",
    "    len_q2 = len(q2)\n",
    "\n",
    "    res = dict(\n",
    "        num_exact_nums_match=num_exact_nums_match,\n",
    "        math_pattern_match=math_pattern_match,\n",
    "        is_q1_math=is_q1_math,\n",
    "        is_q2_math=is_q2_math,\n",
    "        is_both_math=is_both_math,\n",
    "        length_diff=abs(len_q1 - len_q2),\n",
    "        len_q1=len_q1,\n",
    "        len_q2=len_q2,\n",
    "        word_num_diff=abs(num_terms_q1 - num_terms_q2),\n",
    "        num_terms_q1=num_terms_q1,\n",
    "        num_terms_q2=num_terms_q2,\n",
    "#         sim_caps_rate=sim_caps_rate,\n",
    "#         mean_caps_q1=mean_caps_q1,\n",
    "#         mean_caps_q2=mean_caps_q2,\n",
    "#         num_caps_q1=num_caps_q1,\n",
    "#         num_caps_q2=num_caps_q2,\n",
    "    )\n",
    "    \n",
    "    # res.update(n_q1)\n",
    "    # res.update(n_q2)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "heuristics_feature_names = [\n",
    "    'num_exact_nums_match',\n",
    "    'math_pattern_match',\n",
    "    'is_q1_math',\n",
    "    'is_q2_math',\n",
    "    'is_both_math',\n",
    "    'length_diff',\n",
    "    'len_q1',\n",
    "    'len_q2',\n",
    "    'word_num_diff',\n",
    "    'num_terms_q1',\n",
    "    'num_terms_q2',\n",
    "]\n",
    "\n",
    "\n",
    "def score_row(row, check_stops=False, swap=False):\n",
    "    ix, row = row\n",
    "\n",
    "    q1 = row.question1\n",
    "    q2 = row.question2\n",
    "    \n",
    "    ns_q1 = [i for i in q1.lower().split() if i not in stops]\n",
    "    ns_q2 = [i for i in q1.lower().split() if i not in stops]\n",
    "\n",
    "    if not all([ns_q1, ns_q2]) and check_stops:\n",
    "        if ix % 5 == 0:\n",
    "            # 39405\n",
    "            print('here! {}'.format(ix))\n",
    "\n",
    "        return {i: np.nan for i in heuristics_feature_names}\n",
    "    \n",
    "    ns_q1 = ' '.join(ns_q1)\n",
    "    ns_q2 = ' '.join(ns_q2)\n",
    "\n",
    "    return get_heuristic_scores(q1, q2, ns_q1, ns_q2, swap=swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do people hate Hillary Clinton?\n",
      "What are the reasons that people dislike Hillary Clinton?\n",
      "set(['hillary', 'hate', 'clinton?', 'people'])\n",
      "set(['reasons', 'hillary', 'dislike', 'clinton?', 'people'])\n",
      "1\n",
      "{'is_q2_math': 0, 'math_pattern_match': 0, 'is_q1_math': 0, 'length_diff': 22, 'num_terms_q1': 6, 'num_terms_q2': 9, 'is_both_math': 0, 'num_exact_nums_match': 0, 'word_num_diff': 3, 'len_q1': 35, 'len_q2': 57}\n"
     ]
    }
   ],
   "source": [
    "ix =  203\n",
    "row = train_df.ix[ix]\n",
    "q1 = row.question1\n",
    "q2 = row.question2\n",
    "print q1\n",
    "print q2\n",
    "print set(q1.lower().split()).difference(stops)\n",
    "print set(q2.lower().split()).difference(stops)\n",
    "print row.is_duplicate\n",
    "print score_row((ix, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ds = []\n",
    "# # samp = train_df[404000:]\n",
    "# samp = train_df.head(200000)  # [30000:50000]\n",
    "# for row in samp.iterrows():\n",
    "#     ds.append(score_row(row))\n",
    "\n",
    "# ds = pd.DataFrame(ds, index=samp.index)\n",
    "# #ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def score_heuristic_batch(samp_index, is_train):\n",
    "    dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "    if is_train:\n",
    "        samp = dataset_store.select('train_df', where=samp_index)\n",
    "    else:\n",
    "        samp = dataset_store.select('test_df', where=samp_index)\n",
    "    dataset_store.close()\n",
    "\n",
    "    heuristics_scores = []\n",
    "\n",
    "    for row in samp.iterrows():\n",
    "#         if row[0] and row[0] % 10000 == 0:\n",
    "#             print(row[0])\n",
    "\n",
    "        heuristics_scores.append(score_row(row))\n",
    "\n",
    "    heuristics_scores = pd.DataFrame(heuristics_scores, index=samp.index)\n",
    "\n",
    "    return heuristics_scores\n",
    "\n",
    "\n",
    "def heuristic_score_parallel_interface(t_df, is_train):\n",
    "    return delayed(score_heuristic_batch)(t_df.index, is_train)\n",
    "\n",
    "\n",
    "def tfidf_score_parallel_interface(t_df, is_train):\n",
    "    return delayed(get_tfidf_features)(t_df)\n",
    "\n",
    "\n",
    "def parallel_scorer(samp, scorer_interface, is_train, batch, num_proc):\n",
    "    # Consumes 1.5G for batch=1000 and num_proc=4 for tfidf interface\n",
    "    # Use tfidf_features::batch=10000, heuristic_features::batch=20000\n",
    "    # scorer_interface::[heuristic_score_parallel_interface, tfidf_score_parallel_interface]\n",
    "    # Adjust batch depending on the interface used since the memory is dependent on the batch used.\n",
    "\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(scorer_interface(t_df, is_train))\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n",
    "\n",
    "\n",
    "def parallel_get_heuristic_scores(samp, is_train, batch=10000, num_proc=4):\n",
    "    return parallel_scorer(samp, heuristic_score_parallel_interface, is_train, batch, num_proc)\n",
    "\n",
    "\n",
    "def parallel_get_tfidf_scores(samp, is_train, batch=40000, num_proc=4):\n",
    "    # The batch size for the size of the dataset should be large to maximize effect of parallelization.\n",
    "    # The batch here is different from the batch used in the method `get_tfidf_features`\n",
    "    return parallel_scorer(samp, tfidf_score_parallel_interface, is_train, batch, num_proc)\n",
    "\n",
    "\n",
    "NUM_PROC = max(1, mp.cpu_count() - 1)\n",
    "\n",
    "def parallel_get_features(samp, is_train, tfidf_sample_batch=40000, heuristics_sample_batch=10000):\n",
    "    start_time = time.time()\n",
    "\n",
    "    tfidf_features = parallel_get_tfidf_scores(samp, is_train, batch=tfidf_sample_batch, num_proc=NUM_PROC)\n",
    "    print('Finished computing tfidf features after {} seconds.'.format((time.time() - start_time)))\n",
    "\n",
    "    heuristics_scores = parallel_get_heuristic_scores(samp, is_train, batch=heuristics_sample_batch, num_proc=NUM_PROC)\n",
    "    print('Finished computing heuristic features after {} seconds.'.format((time.time() - start_time)))\n",
    "\n",
    "    features = pd.concat([tfidf_features, heuristics_scores], axis=1)\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_features(samp):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tfidf_features = get_tfidf_features(samp)\n",
    "    print('Finished computing tfidf features after {} seconds.'.format((time.time() - start_time)))\n",
    "\n",
    "    heuristics_scores = []\n",
    "\n",
    "    for row in samp.iterrows():\n",
    "        if row[0] and row[0] % 10000 == 0:\n",
    "            print(row[0])\n",
    "  \n",
    "        heuristics_scores.append(score_row(row))\n",
    "\n",
    "    heuristics_scores = pd.DataFrame(heuristics_scores, index=samp.index)\n",
    "    \n",
    "    features = pd.concat([tfidf_features, heuristics_scores], axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# samp = train_df\n",
    "\n",
    "# X_train = get_features(samp)\n",
    "# y_train = samp.is_duplicate\n",
    "\n",
    "# log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57755"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "GB = 1000000000.0  # Not really GB :D\n",
    "SAVE_GB = 1.5 * GB\n",
    "\n",
    "def get_tfidf_batch_size(df, NUM_PROC):\n",
    "    # Memory (4.2 - 2.01 = 2.19G) used with 7 processes and 404290 rows (train) with batch size 57755\n",
    "\n",
    "    mem_per_row = 2.19 / 57755 / 7\n",
    "    available_mem = (psutil.virtual_memory().available - SAVE_GB) / GB\n",
    "    tfidf_batch_size = df.shape[0] / NUM_PROC\n",
    "    delta = 10000\n",
    "\n",
    "    if (df.shape[0] * mem_per_row) > available_mem:\n",
    "        while (tfidf_batch_size * NUM_PROC * mem_per_row) > available_mem:\n",
    "            tfidf_batch_size -= delta\n",
    "\n",
    "    return tfidf_batch_size\n",
    "\n",
    "NUM_PROC=7\n",
    "train_tfidf_batch_size = get_tfidf_batch_size(train_df, NUM_PROC=NUM_PROC)\n",
    "train_tfidf_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch in main thread: 346530\n",
      "Current batch in main thread: 750815\n",
      "CPU times: user 1.05 s, sys: 200 ms, total: 1.25 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtfidf = parallel_get_tfidf_scores(train_df, is_train=True, batch=train_tfidf_batch_size, num_proc=NUM_PROC)\n",
    "# get_tfidf_features(train_df.head(60000), batch=1000)  # , num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch in main thread: 346530\n",
      "Current batch in main thread: 750815\n",
      "CPU times: user 132 ms, sys: 200 ms, total: 332 ms\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dheur = parallel_get_heuristic_scores(train_df, is_train=True, batch=train_tfidf_batch_size, num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# heuristics_scores = []\n",
    "# samp = train_df[404285: 404293]\n",
    "# for row in samp.iterrows():\n",
    "#     if row[0] and row[0] % 10000 == 0:\n",
    "#         print(row[0])\n",
    "\n",
    "#     heuristics_scores.append(score_row(row))\n",
    "# heuristics_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=410000, stop=440000, step=1)\n"
     ]
    }
   ],
   "source": [
    "ix = 410000\n",
    "batch = 30000\n",
    "samp = test_df[ix: ix + batch]\n",
    "print(samp.index)\n",
    "dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "# sp = dataset_store.select('train_df', where=samp.index)\n",
    "sp = dataset_store.select('test_df', where=samp.index)\n",
    "dataset_store.close()\n",
    "# sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch in main thread: 346530\n",
      "Current batch in main thread: 750815\n",
      "Finished computing tfidf features after 41.7312591076 seconds.\n",
      "Current batch in main thread: 346530\n",
      "Current batch in main thread: 750815\n",
      "Finished computing heuristic features after 54.2434220314 seconds.\n",
      "Current all-time max memory: 2115 MB\n",
      "CPU times: user 1.04 s, sys: 376 ms, total: 1.42 s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_batch_size = get_tfidf_batch_size(train_df, NUM_PROC=NUM_PROC)\n",
    "\n",
    "X_train = parallel_get_features(\n",
    "    train_df, is_train=True, tfidf_sample_batch=train_batch_size, heuristics_sample_batch=train_batch_size\n",
    ")\n",
    "y_train = train_df.is_duplicate\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_train = get_features(samp)\n",
    "# y_train = samp.is_duplicate\n",
    "\n",
    "# log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 2115 MB\n"
     ]
    }
   ],
   "source": [
    "train_sample_dist = train_df.groupby('is_duplicate').count()['id']\n",
    "\n",
    "p = 0.165\n",
    "a = train_sample_dist[1]\n",
    "b = train_sample_dist[0]\n",
    "\n",
    "neg_extra = int((a / p) - b)\n",
    "neg_extra_ind = np.random.choice(train_df[train_df.is_duplicate == 0].index, size=neg_extra, replace=True)\n",
    "\n",
    "os_X_train = pd.concat([X_train, X_train.ix[neg_extra_ind]])\n",
    "os_y_train = pd.concat([y_train, y_train.ix[neg_extra_ind]])\n",
    "\n",
    "os_X_train, X_valid, os_y_train, y_valid = train_test_split(os_X_train, os_y_train, test_size=0.2, random_state=1029)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210778,)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss, roc_auc_score, make_scorer\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "char_lm_model = LogisticRegression(C=100)\n",
    "word_lm_model = LogisticRegression(C=1)\n",
    "length_diff_lm_model = LogisticRegression(C=1)\n",
    "word_num_diff_lm_model = LogisticRegression(C=1)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, min_samples_leaf=2, min_samples_split=3, n_jobs=NUM_PROC)\n",
    "lm_model = LogisticRegression()\n",
    "\n",
    "def log_loss_scorer(model, X, y):\n",
    "    return log_loss(y, model.predict_proba(X))\n",
    "\n",
    "def fit_models(X, y):\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    char_lm_model.fit(X_train.cv.values.reshape(-1, 1), y_train)\n",
    "    word_lm_model.fit(X_train.wv.values.reshape(-1, 1), y_train)\n",
    "    length_diff_lm_model.fit(X_train.length_diff.values.reshape(-1, 1), y_train)\n",
    "    word_num_diff_lm_model.fit(X_train.word_num_diff.values.reshape(-1, 1), y_train)\n",
    "\n",
    "def predict(X):\n",
    "#     weights = dict(zip(X.columns, rf_model.feature_importances_))\n",
    "    char_pred = char_lm_model.predict_proba(X.cv.values.reshape(-1, 1))[:, 1] # * weights['cv']\n",
    "    word_pred = word_lm_model.predict_proba(X.wv.values.reshape(-1, 1))[:, 1] # * weights['wv']\n",
    "    length_diff_pred = length_diff_lm_model.predict_proba(X.length_diff.values.reshape(-1, 1))[:, 1] # * weights['length_diff']\n",
    "    word_num_diff_pred = word_num_diff_lm_model.predict_proba(X.word_num_diff.values.reshape(-1, 1))[:, 1] # * weights['word_num_diff']\n",
    "    rf_pred = rf_model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return [char_pred, word_pred, length_diff_pred, word_num_diff_pred, rf_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.344890944025\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm_model.fit(os_X_train, os_y_train)\n",
    "\n",
    "print(log_loss_scorer(lm_model, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211987538739\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_model.fit(os_X_train, os_y_train)\n",
    "\n",
    "print(log_loss_scorer(rf_model, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24221531  0.24187433  0.24231307]\n",
      "CPU times: user 11min 7s, sys: 1.11 s, total: 11min 9s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit_models(X_train, y_train)\n",
    "cvs = cross_val_score(rf_model, os_X_train, os_y_train, scoring=log_loss_scorer)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999755690807\n",
      "0.954475840628\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(os_y_train, rf_model.predict_proba(os_X_train)[:, 1]))\n",
    "print(roc_auc_score(y_valid, rf_model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(log_loss(y_test, np.mean(predict(X_test), axis=0)))\n",
    "# print(roc_auc_score(y_test, np.mean(predict(X_test), axis=0)))\n",
    "# print(roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]))\n",
    "# print(sum((y_test - (1 * (rf_model.predict_proba(X_test)[:, 1] < 0.5))) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i, j in sorted(list(zip(X_test.columns, rf_model.feature_importances_)), key=lambda x: x[1], reverse=True):\n",
    "#     print i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.concat([features, samp.is_duplicate], axis=1).groupby('is_duplicate').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_df.fillna('zxzxzx zxzxzx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.802260753419575"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 * test_df.shape[0] / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tes batch size: 255113\n",
      "Current batch in main thread: 1530678\n",
      "Current batch in main thread: 3316469\n",
      "Finished computing tfidf features after 263.97646594 seconds.\n",
      "Current batch in main thread: 1530678\n",
      "Current batch in main thread: 3316469\n",
      "Finished computing heuristic features after 356.002717018 seconds.\n",
      "Current all-time max memory: 4982 MB\n",
      "CPU times: user 4.98 s, sys: 1.1 s, total: 6.08 s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_batch_size = get_tfidf_batch_size(test_df, NUM_PROC=NUM_PROC)\n",
    "print('Tes batch size: {}'.format(test_batch_size))\n",
    "\n",
    "X_test = parallel_get_features(\n",
    "    test_df, is_train=False, tfidf_sample_batch=test_batch_size, heuristics_sample_batch=test_batch_size\n",
    ")\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/anaconda/lib/python2.7/site-packages/tables/path.py:100: NaturalNameWarning: object name is not a valid Python identifier: 'test-features-X_test'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 164 ms, total: 292 ms\n",
      "Wall time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test.to_hdf('kaggle-quora', 'test-features-X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_id = test_df.test_id\n",
    "\n",
    "# del(test_df)\n",
    "# del(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.119348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.160049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.027189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.046317\n",
       "1        1      0.119348\n",
       "2        2      0.160049\n",
       "3        3      0.030699\n",
       "4        4      0.027189"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "lm_sub = pd.DataFrame()\n",
    "\n",
    "lm_sub['test_id'] = test_id\n",
    "lm_sub['is_duplicate'] = lm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lm_sub.to_csv('lm_submission_{}.csv'.format(datetime.now()), index=False)\n",
    "lm_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.365262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.149548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.173174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.048285\n",
       "1        1      0.365262\n",
       "2        2      0.149548\n",
       "3        3      0.005025\n",
       "4        4      0.173174"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # %%time\n",
    "# rf_sub = pd.DataFrame()\n",
    "\n",
    "# rf_sub['test_id'] = test_id\n",
    "# rf_sub['is_duplicate'] = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# rf_sub.to_csv('rf_submission.csv', index=False)\n",
    "# rf_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.302941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.198157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.024167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.132272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.026000\n",
       "1        1      0.302941\n",
       "2        2      0.198157\n",
       "3        3      0.024167\n",
       "4        4      0.132272"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "rf_sub = pd.DataFrame()\n",
    "\n",
    "rf_sub['test_id'] = test_id\n",
    "rf_sub['is_duplicate'] = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_sub.to_csv('rf_submission_{}.csv'.format(datetime.now()), index=False)\n",
    "rf_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>By scrapping the 500 and 1000 rupee notes, how...</td>\n",
       "      <td>How will the recent move to declare 500 and 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>What are the how best books of all time?</td>\n",
       "      <td>What are some of the military history books of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>What is the best slideshow app for Android?</td>\n",
       "      <td>What are the best app for android?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Can a vacuum cleaner concentrate suck your eye...</td>\n",
       "      <td>Could a vacuum cleaner suck get your eye out i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>What site the best example of dedication in an...</td>\n",
       "      <td>What are some of the best examples of new in a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_id                                          question1  \\\n",
       "7         7  By scrapping the 500 and 1000 rupee notes, how...   \n",
       "8         8           What are the how best books of all time?   \n",
       "10       10        What is the best slideshow app for Android?   \n",
       "17       17  Can a vacuum cleaner concentrate suck your eye...   \n",
       "35       35  What site the best example of dedication in an...   \n",
       "\n",
       "                                            question2  \n",
       "7   How will the recent move to declare 500 and 10...  \n",
       "8   What are some of the military history books of...  \n",
       "10                 What are the best app for android?  \n",
       "17  Could a vacuum cleaner suck get your eye out i...  \n",
       "35  What are some of the best examples of new in a...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[rf_sub.is_duplicate > 0.4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684519662921\n",
      "By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money?\n",
      "How will the recent move to declare 500 and 1000 denomination lewin illegal will curb black money?\n",
      "()\n",
      "0.48367564957\n",
      "What are the how best books of all time?\n",
      "What are some of the military history books of all time?\n",
      "()\n",
      "0.570220336466\n",
      "What is the best slideshow app for Android?\n",
      "What are the best app for android?\n",
      "()\n",
      "0.755877344877\n",
      "Can a vacuum cleaner concentrate suck your eye out if it is pressed against your face?\n",
      "Could a vacuum cleaner suck get your eye out if directly pressed on the face?\n",
      "()\n",
      "0.587628221401\n",
      "What site the best example of dedication in any field?\n",
      "What are some of the best examples of new in any field?\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "for r in test_df[rf_sub.is_duplicate > 0.4].head().iterrows():\n",
    "    ix, r = r\n",
    "    print(rf_sub.ix[ix].is_duplicate)\n",
    "    print(r.question1)\n",
    "    print(r.question2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n",
    "scores_data = []\n",
    "samp = train_df\n",
    "\n",
    "for row in samp.iterrows():\n",
    "    if row[0] % 5000 == 0:\n",
    "        print(row[0])\n",
    "\n",
    "    scores_data.append(score_row(row))\n",
    "\n",
    "X = pd.DataFrame(scores_data)\n",
    "is_duplicate_test = np.mean(predict(X), axis=0)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
