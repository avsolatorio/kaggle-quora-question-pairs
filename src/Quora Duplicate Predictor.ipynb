{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "sample_submission.csv.zip\n",
      "test.csv\n",
      "test.csv.zip\n",
      "train.csv\n",
      "train.csv.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import resource\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# ------- Define modular methods for the task\n",
    "def log_max_mem_usage():\n",
    "    print(\n",
    "        \"Current all-time max memory: {} MB\".format(\n",
    "            resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df.fillna('zxzxzx zxzxzx', inplace=True) # For id: qid2 174364\n",
    "\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "test_df.fillna('zxzxzx zxzxzx', inplace=True)\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 15.8 s, total: 31.4 s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset_store = pd.HDFStore('../input/dataset.hdf', mode='w')\n",
    "dataset_store.append('train_df', train_df)\n",
    "dataset_store.append('test_df', test_df)\n",
    "dataset_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  qid1  qid2                                          question1  \\\n",
      "10  10    21    22  Method to find separation of slits using fresn...   \n",
      "11  11    23    24        How do I read and find my YouTube comments?   \n",
      "12  12    25    26               What can make Physics easy to learn?   \n",
      "13  13    27    28        What was your first sexual experience like?   \n",
      "14  14    29    30  What are the laws to change your status from a...   \n",
      "15  15    31    32  What would a Trump presidency mean for current...   \n",
      "16  16    33    34                       What does manipulation mean?   \n",
      "17  17    35    36  Why do girls want to be friends with the guy t...   \n",
      "18  18    37    38  Why are so many Quora users posting questions ...   \n",
      "19  19    39    40  Which is the best digital marketing institutio...   \n",
      "\n",
      "                                            question2  is_duplicate  \n",
      "10  What are some of the things technicians can te...             0  \n",
      "11             How can I see all my Youtube comments?             1  \n",
      "12            How can you make physics easy to learn?             1  \n",
      "13             What was your first sexual experience?             1  \n",
      "14  What are the laws to change your status from a...             0  \n",
      "15  How will a Trump presidency affect the student...             1  \n",
      "16                      What does manipulation means?             1  \n",
      "17           How do guys feel after rejecting a girl?             0  \n",
      "18  Why do people ask Quora questions which can be...             1  \n",
      "19  Which is the best digital marketing institute ...             0  \n",
      "CPU times: user 52 ms, sys: 0 ns, total: 52 ms\n",
      "Wall time: 886 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "dd = dataset_store.select('train_df', where=train_df.index[10:20])\n",
    "dataset_store.close()\n",
    "print dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# def score_heuristic_batch(samp_index):\n",
    "#     dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "#     samp = dataset_store.select('train_df', where=samp_index)\n",
    "#     dataset_store.close()\n",
    "\n",
    "#     heuristics_scores = []\n",
    "\n",
    "#     for row in samp.iterrows():\n",
    "# #         if row[0] and row[0] % 10000 == 0:\n",
    "# #             print(row[0])\n",
    "#         heuristics_scores.append(score_row(row))\n",
    "\n",
    "#     heuristics_scores = pd.DataFrame(heuristics_scores, index=samp.index)\n",
    "\n",
    "#     return heuristics_scores\n",
    "\n",
    "\n",
    "# def heuristic_score_parallel_interface(t_df):\n",
    "#     return delayed(score_heuristic_batch)(t_df.index)\n",
    "\n",
    "\n",
    "# def tfidf_score_parallel_interface(t_df):\n",
    "#     return delayed(get_tfidf_features)(t_df)\n",
    "\n",
    "\n",
    "# def parallel_scorer(samp, scorer_interface, batch, num_proc):\n",
    "#     # Consumes 1.5G for batch=1000 and num_proc=4 for tfidf interface\n",
    "#     # Use tfidf_features::batch=1000, heuristic_features::batch=20000\n",
    "#     # scorer_interface::[heuristic_score_parallel_interface, tfidf_score_parallel_interface]\n",
    "#     # Adjust batch depending on the interface used since the memory is dependent on the batch used.\n",
    "\n",
    "#     with Parallel(n_jobs=num_proc) as parallel:\n",
    "#         dataset = []\n",
    "#         is_break = False\n",
    "#         i = 0\n",
    "\n",
    "#         while not is_break:\n",
    "#             payload = []\n",
    "\n",
    "#             for j in xrange(num_proc):\n",
    "#                 t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "#                 if t_df.empty:\n",
    "#                     is_break = True\n",
    "#                     continue\n",
    "\n",
    "#                 payload.append(scorer_interface(t_df))\n",
    "#             print((i + j) * batch)\n",
    "\n",
    "#             if payload:\n",
    "#                 results = parallel(payload)\n",
    "#                 dataset.extend(results)\n",
    "#                 i += num_proc\n",
    "\n",
    "#     return pd.concat(dataset)\n",
    "\n",
    "\n",
    "# def parallel_get_heuristic_scores(samp, batch=10000, num_proc=4):\n",
    "#     return parallel_scorer(samp, heuristic_score_parallel_interface, batch, num_proc)\n",
    "\n",
    "\n",
    "# def parallel_get_tfidf_scores(samp, batch=1000, num_proc=4):\n",
    "#     return parallel_scorer(samp, tfidf_score_parallel_interface, batch, num_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# d = parallel_get_heuristic_scores(train_df.head(200000), batch=10000, num_proc=4)\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 6660 MB\n"
     ]
    }
   ],
   "source": [
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current all-time max memory: 6660 MB\n",
      "CPU times: user 2min 2s, sys: 2.69 s, total: 2min 4s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "unique_questions = pd.Series(pd.concat([train_df.question1, train_df.question2]).unique())\n",
    "# combined_featurizers.fit(unique_questions)\n",
    "\n",
    "char_tfidf = TfidfVectorizer(analyzer='char', ngram_range=(2, 3))  # featurizers[0][1]\n",
    "word_tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))  # featurizers[1][1]\n",
    "char_tfidf.fit(unique_questions)\n",
    "word_tfidf.fit(unique_questions)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# d = get_tfidf_features(train_df[:100000], batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "num_pattern = re.compile('[0-9]+')\n",
    "math_pattern = re.compile('\\[math\\](.*)\\[\\/math\\]')\n",
    "\n",
    "nums = '01234567890'\n",
    "\n",
    "\n",
    "def get_tfidf_features(data_df, batch=1000):\n",
    "    # data_df size should be about 40000 when used in parallel to observe effects of optimization.\n",
    "    i = 0\n",
    "#     print('Current data size in `get_tfidf_features`: {}'.format(data_df.shape[0]))\n",
    "\n",
    "    word_dataset = np.array([])\n",
    "    char_dataset = np.array([])\n",
    "\n",
    "    while True:\n",
    "        samp = data_df[i * batch: (i + 1) * batch]\n",
    "        i += 1\n",
    "#         print_batch = i * batch % 10000\n",
    "\n",
    "#         if print_batch == 0:\n",
    "#             print('Batch process in `get_tfidf_features`: {}'.format(i * batch))\n",
    "\n",
    "        if samp.empty:\n",
    "            break\n",
    "\n",
    "        word_res = np.dot(\n",
    "            word_tfidf.transform(samp.question1),\n",
    "            word_tfidf.transform(samp.question2).T\n",
    "        ).diagonal()\n",
    "        \n",
    "        char_res = np.dot(\n",
    "            char_tfidf.transform(samp.question1),\n",
    "            char_tfidf.transform(samp.question2).T\n",
    "        ).diagonal()\n",
    "\n",
    "        word_dataset = np.concatenate([word_dataset, word_res])\n",
    "        char_dataset = np.concatenate([char_dataset, char_res])\n",
    "\n",
    "    return pd.DataFrame(dict(wv=word_dataset, cv=char_dataset), index=data_df.index)\n",
    "\n",
    "\n",
    "def get_heuristic_scores(q1, q2, ns_q1, ns_q2, swap):\n",
    "#     n_q1 = {}\n",
    "#     n_q2 = {}\n",
    "\n",
    "#     for n in nums:\n",
    "#         qc1 = q1.count(n)\n",
    "#         qc2 = q2.count(n)\n",
    "#         n_q1['q1_{}'.format(n)] = qc1\n",
    "#         n_q2['q2_{}'.format(n)] = qc2\n",
    "\n",
    "    if swap:\n",
    "        q1 = ns_q1\n",
    "        q2 = ns_q2\n",
    "\n",
    "    exact_nums_q1 = num_pattern.findall(q1)\n",
    "    exact_nums_q2 = num_pattern.findall(q2)\n",
    "    \n",
    "    math_q1 = math_pattern.findall(q1)\n",
    "    math_q2 = math_pattern.findall(q2)\n",
    "\n",
    "    num_exact_nums_match = len([n1 for n1 in exact_nums_q1 if n1 in exact_nums_q2])\n",
    "    math_pattern_match = len([n1 for n1 in math_q1 if n1 in math_q2])\n",
    "    \n",
    "    is_q1_math = 1 * any(math_q1)\n",
    "    is_q2_math = 1 * any(math_q2)\n",
    "    is_both_math = is_q1_math * is_q2_math\n",
    "\n",
    "#     qq2 = pd.Series(Counter([s for s in q1 if s.isupper()]))\n",
    "#     qq1 = pd.Series(Counter([s for s in q2 if s.isupper()]))\n",
    "    \n",
    "#     sim_caps_rate = (qq1/qq2).mean()\n",
    "#     num_caps_q1 = qq1.sum() \n",
    "#     num_caps_q2 = qq2.sum()\n",
    "\n",
    "#     mean_caps_q1 = qq1.mean() \n",
    "#     mean_caps_q2 = qq2.mean()\n",
    "    \n",
    "    num_terms_q1 = len(q1.split())\n",
    "    num_terms_q2 = len(q2.split())\n",
    "    \n",
    "    len_q1 = len(q1)\n",
    "    len_q2 = len(q2)\n",
    "\n",
    "    res = dict(\n",
    "        num_exact_nums_match=num_exact_nums_match,\n",
    "        math_pattern_match=math_pattern_match,\n",
    "        is_q1_math=is_q1_math,\n",
    "        is_q2_math=is_q2_math,\n",
    "        is_both_math=is_both_math,\n",
    "        length_diff=abs(len_q1 - len_q2),\n",
    "        len_q1=len_q1,\n",
    "        len_q2=len_q2,\n",
    "        word_num_diff=abs(num_terms_q1 - num_terms_q2),\n",
    "        num_terms_q1=num_terms_q1,\n",
    "        num_terms_q2=num_terms_q2,\n",
    "#         sim_caps_rate=sim_caps_rate,\n",
    "#         mean_caps_q1=mean_caps_q1,\n",
    "#         mean_caps_q2=mean_caps_q2,\n",
    "#         num_caps_q1=num_caps_q1,\n",
    "#         num_caps_q2=num_caps_q2,\n",
    "    )\n",
    "    \n",
    "    # res.update(n_q1)\n",
    "    # res.update(n_q2)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "heuristics_feature_names = [\n",
    "    'num_exact_nums_match',\n",
    "    'math_pattern_match',\n",
    "    'is_q1_math',\n",
    "    'is_q2_math',\n",
    "    'is_both_math',\n",
    "    'length_diff',\n",
    "    'len_q1',\n",
    "    'len_q2',\n",
    "    'word_num_diff',\n",
    "    'num_terms_q1',\n",
    "    'num_terms_q2',\n",
    "]\n",
    "\n",
    "\n",
    "def score_row(row, check_stops=False, swap=False):\n",
    "    ix, row = row\n",
    "\n",
    "    q1 = row.question1\n",
    "    q2 = row.question2\n",
    "    \n",
    "    ns_q1 = [i for i in q1.lower().split() if i not in stops]\n",
    "    ns_q2 = [i for i in q1.lower().split() if i not in stops]\n",
    "\n",
    "    if not all([ns_q1, ns_q2]) and check_stops:\n",
    "        if ix % 5 == 0:\n",
    "            # 39405\n",
    "            print('here! {}'.format(ix))\n",
    "\n",
    "        return {i: np.nan for i in heuristics_feature_names}\n",
    "    \n",
    "    ns_q1 = ' '.join(ns_q1)\n",
    "    ns_q2 = ' '.join(ns_q2)\n",
    "\n",
    "    return get_heuristic_scores(q1, q2, ns_q1, ns_q2, swap=swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do people hate Hillary Clinton?\n",
      "What are the reasons that people dislike Hillary Clinton?\n",
      "set(['hillary', 'hate', 'clinton?', 'people'])\n",
      "set(['reasons', 'hillary', 'dislike', 'clinton?', 'people'])\n",
      "1\n",
      "{'is_q2_math': 0, 'math_pattern_match': 0, 'is_q1_math': 0, 'length_diff': 22, 'num_terms_q1': 6, 'num_terms_q2': 9, 'is_both_math': 0, 'num_exact_nums_match': 0, 'word_num_diff': 3, 'len_q1': 35, 'len_q2': 57}\n"
     ]
    }
   ],
   "source": [
    "ix =  203\n",
    "row = train_df.ix[ix]\n",
    "q1 = row.question1\n",
    "q2 = row.question2\n",
    "print q1\n",
    "print q2\n",
    "print set(q1.lower().split()).difference(stops)\n",
    "print set(q2.lower().split()).difference(stops)\n",
    "print row.is_duplicate\n",
    "print score_row((ix, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ds = []\n",
    "# # samp = train_df[404000:]\n",
    "# samp = train_df.head(200000)  # [30000:50000]\n",
    "# for row in samp.iterrows():\n",
    "#     ds.append(score_row(row))\n",
    "\n",
    "# ds = pd.DataFrame(ds, index=samp.index)\n",
    "# #ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def score_heuristic_batch(samp_index, is_train):\n",
    "    dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "    if is_train:\n",
    "        samp = dataset_store.select('train_df', where=samp_index)\n",
    "    else:\n",
    "        samp = dataset_store.select('test_df', where=samp_index)\n",
    "    dataset_store.close()\n",
    "\n",
    "    heuristics_scores = []\n",
    "\n",
    "    for row in samp.iterrows():\n",
    "#         if row[0] and row[0] % 10000 == 0:\n",
    "#             print(row[0])\n",
    "\n",
    "        heuristics_scores.append(score_row(row))\n",
    "\n",
    "    heuristics_scores = pd.DataFrame(heuristics_scores, index=samp.index)\n",
    "\n",
    "    return heuristics_scores\n",
    "\n",
    "\n",
    "def heuristic_score_parallel_interface(t_df, is_train):\n",
    "    return delayed(score_heuristic_batch)(t_df.index, is_train)\n",
    "\n",
    "\n",
    "def tfidf_score_parallel_interface(t_df, is_train):\n",
    "    return delayed(get_tfidf_features)(t_df)\n",
    "\n",
    "\n",
    "def parallel_scorer(samp, scorer_interface, is_train, batch, num_proc):\n",
    "    # Consumes 1.5G for batch=1000 and num_proc=4 for tfidf interface\n",
    "    # Use tfidf_features::batch=10000, heuristic_features::batch=20000\n",
    "    # scorer_interface::[heuristic_score_parallel_interface, tfidf_score_parallel_interface]\n",
    "    # Adjust batch depending on the interface used since the memory is dependent on the batch used.\n",
    "\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(scorer_interface(t_df, is_train))\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n",
    "\n",
    "\n",
    "def parallel_get_heuristic_scores(samp, is_train, batch=10000, num_proc=4):\n",
    "    return parallel_scorer(samp, heuristic_score_parallel_interface, is_train, batch, num_proc)\n",
    "\n",
    "\n",
    "def parallel_get_tfidf_scores(samp, is_train, batch=40000, num_proc=4):\n",
    "    # The batch size for the size of the dataset should be large to maximize effect of parallelization.\n",
    "    # The batch here is different from the batch used in the method `get_tfidf_features`\n",
    "    return parallel_scorer(samp, tfidf_score_parallel_interface, is_train, batch, num_proc)\n",
    "\n",
    "\n",
    "NUM_PROC = max(1, mp.cpu_count() - 1)\n",
    "\n",
    "def parallel_get_features(samp, is_train, tfidf_sample_batch=40000, heuristics_sample_batch=10000):\n",
    "    start_time = time.time()\n",
    "\n",
    "    tfidf_features = parallel_get_tfidf_scores(samp, is_train, batch=tfidf_sample_batch, num_proc=NUM_PROC)\n",
    "    print('Finished computing tfidf features after {} seconds.'.format((time.time() - start_time)))\n",
    "\n",
    "    heuristics_scores = parallel_get_heuristic_scores(samp, is_train, batch=heuristics_sample_batch, num_proc=NUM_PROC)\n",
    "    print('Finished computing heuristic features after {} seconds.'.format((time.time() - start_time)))\n",
    "\n",
    "    features = pd.concat([tfidf_features, heuristics_scores], axis=1)\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_features(samp):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tfidf_features = get_tfidf_features(samp)\n",
    "    print('Finished computing tfidf features after {} seconds.'.format((time.time() - start_time)))\n",
    "\n",
    "    heuristics_scores = []\n",
    "\n",
    "    for row in samp.iterrows():\n",
    "        if row[0] and row[0] % 10000 == 0:\n",
    "            print(row[0])\n",
    "  \n",
    "        heuristics_scores.append(score_row(row))\n",
    "\n",
    "    heuristics_scores = pd.DataFrame(heuristics_scores, index=samp.index)\n",
    "    \n",
    "    features = pd.concat([tfidf_features, heuristics_scores], axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# samp = train_df\n",
    "\n",
    "# X_train = get_features(samp)\n",
    "# y_train = samp.is_duplicate\n",
    "\n",
    "# log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# parallel_get_tfidf_scores(train_df.head(60000), batch=30000, num_proc=NUM_PROC)\n",
    "# get_tfidf_features(train_df.head(60000), batch=1000)  # , num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# heuristics_scores = []\n",
    "# samp = train_df[404285: 404293]\n",
    "# for row in samp.iterrows():\n",
    "#     if row[0] and row[0] % 10000 == 0:\n",
    "#         print(row[0])\n",
    "\n",
    "#     heuristics_scores.append(score_row(row))\n",
    "# heuristics_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=410000, stop=440000, step=1)\n"
     ]
    }
   ],
   "source": [
    "ix = 410000\n",
    "batch = 30000\n",
    "samp = test_df[ix: ix + batch]\n",
    "print(samp.index)\n",
    "dataset_store = pd.HDFStore('../input/dataset.hdf', mode='r')\n",
    "# sp = dataset_store.select('train_df', where=samp.index)\n",
    "sp = dataset_store.select('test_df', where=samp.index)\n",
    "dataset_store.close()\n",
    "# sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch in main thread: 80000\n",
      "Current batch in main thread: 200000\n",
      "Current batch in main thread: 320000\n",
      "Current batch in main thread: 440000\n",
      "Finished computing tfidf features after 147.836364031 seconds.\n",
      "Current batch in main thread: 20000\n",
      "Current batch in main thread: 50000\n",
      "Current batch in main thread: 80000\n",
      "Current batch in main thread: 110000\n",
      "Current batch in main thread: 140000\n",
      "Current batch in main thread: 170000\n",
      "Current batch in main thread: 200000\n",
      "Current batch in main thread: 230000\n",
      "Current batch in main thread: 260000\n",
      "Current batch in main thread: 290000\n",
      "Current batch in main thread: 320000\n",
      "Current batch in main thread: 350000\n",
      "Current batch in main thread: 380000\n",
      "Current batch in main thread: 410000\n",
      "Finished computing heuristic features after 222.511899948 seconds.\n",
      "Current all-time max memory: 6660 MB\n",
      "CPU times: user 1.84 s, sys: 480 ms, total: 2.32 s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = parallel_get_features(train_df, is_train=True)\n",
    "y_train = train_df.is_duplicate\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_train = get_features(samp)\n",
    "# y_train = samp.is_duplicate\n",
    "\n",
    "# log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23756274561\n",
      "0\n",
      "Current all-time max memory: 6660 MB\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "pos_train = X_train[y_train == 1]\n",
    "neg_train = X_train[y_train == 0]\n",
    "\n",
    "# Now we oversample the negative class\n",
    "# There is likely a much more elegant way to do this...\n",
    "p = 0.165\n",
    "scale = ((1.0 * len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "while scale > 1:\n",
    "    print(scale)\n",
    "    \n",
    "    neg_train = pd.concat([neg_train, neg_train])\n",
    "    scale -=1\n",
    "\n",
    "neg_train = pd.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "print(len(pos_train) / (len(pos_train) + len(neg_train)))\n",
    "\n",
    "X_train = pd.concat([pos_train, neg_train])\n",
    "y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "\n",
    "del pos_train, neg_train\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=1029)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss, roc_auc_score, make_scorer\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "char_lm_model = LogisticRegression(C=100)\n",
    "word_lm_model = LogisticRegression(C=1)\n",
    "length_diff_lm_model = LogisticRegression(C=1)\n",
    "word_num_diff_lm_model = LogisticRegression(C=1)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, min_samples_leaf=2, min_samples_split=3, n_jobs=NUM_PROC)\n",
    "lm_model = LogisticRegression()\n",
    "\n",
    "def log_loss_scorer(model, X, y):\n",
    "    return log_loss(y, model.predict_proba(X))\n",
    "\n",
    "def fit_models(X, y):\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    char_lm_model.fit(X_train.cv.values.reshape(-1, 1), y_train)\n",
    "    word_lm_model.fit(X_train.wv.values.reshape(-1, 1), y_train)\n",
    "    length_diff_lm_model.fit(X_train.length_diff.values.reshape(-1, 1), y_train)\n",
    "    word_num_diff_lm_model.fit(X_train.word_num_diff.values.reshape(-1, 1), y_train)\n",
    "\n",
    "def predict(X):\n",
    "#     weights = dict(zip(X.columns, rf_model.feature_importances_))\n",
    "    char_pred = char_lm_model.predict_proba(X.cv.values.reshape(-1, 1))[:, 1] # * weights['cv']\n",
    "    word_pred = word_lm_model.predict_proba(X.wv.values.reshape(-1, 1))[:, 1] # * weights['wv']\n",
    "    length_diff_pred = length_diff_lm_model.predict_proba(X.length_diff.values.reshape(-1, 1))[:, 1] # * weights['length_diff']\n",
    "    word_num_diff_pred = word_num_diff_lm_model.predict_proba(X.word_num_diff.values.reshape(-1, 1))[:, 1] # * weights['word_num_diff']\n",
    "    rf_pred = rf_model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return [char_pred, word_pred, length_diff_pred, word_num_diff_pred, rf_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.410091383085\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "lm_model.fit(X_train, y_train)\n",
    "\n",
    "print(log_loss_scorer(lm_model, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286679794441\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(log_loss_scorer(rf_model, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# fit_models(X_train, y_train)\n",
    "# cross_val_score(rf_model, X_train, y_train, scoring=log_loss_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925450508732\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_valid, rf_model.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(log_loss(y_test, np.mean(predict(X_test), axis=0)))\n",
    "# print(roc_auc_score(y_test, np.mean(predict(X_test), axis=0)))\n",
    "# print(roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]))\n",
    "# print(sum((y_test - (1 * (rf_model.predict_proba(X_test)[:, 1] < 0.5))) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, j in sorted(list(zip(X_test.columns, rf_model.feature_importances_)), key=lambda x: x[1], reverse=True):\n",
    "#     print i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.concat([features, samp.is_duplicate], axis=1).groupby('is_duplicate').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.fillna('zxzxzx zxzxzx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.802260753419575"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 * test_df.shape[0] / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch in main thread: 80000\n",
      "Current batch in main thread: 200000\n",
      "Current batch in main thread: 320000\n",
      "Current batch in main thread: 440000\n",
      "Current batch in main thread: 560000\n",
      "Current batch in main thread: 680000\n",
      "Current batch in main thread: 800000\n",
      "Current batch in main thread: 920000\n",
      "Current batch in main thread: 1040000\n",
      "Current batch in main thread: 1160000\n",
      "Current batch in main thread: 1280000\n",
      "Current batch in main thread: 1400000\n",
      "Current batch in main thread: 1520000\n",
      "Current batch in main thread: 1640000\n",
      "Current batch in main thread: 1760000\n",
      "Current batch in main thread: 1880000\n",
      "Current batch in main thread: 2000000\n",
      "Current batch in main thread: 2120000\n",
      "Current batch in main thread: 2240000\n",
      "Current batch in main thread: 2360000\n",
      "Finished computing tfidf features after 715.204516172 seconds.\n",
      "Current batch in main thread: 20000\n",
      "Current batch in main thread: 50000\n",
      "Current batch in main thread: 80000\n",
      "Current batch in main thread: 110000\n",
      "Current batch in main thread: 140000\n",
      "Current batch in main thread: 170000\n",
      "Current batch in main thread: 200000\n",
      "Current batch in main thread: 230000\n",
      "Current batch in main thread: 260000\n",
      "Current batch in main thread: 290000\n",
      "Current batch in main thread: 320000\n",
      "Current batch in main thread: 350000\n",
      "Current batch in main thread: 380000\n",
      "Current batch in main thread: 410000\n",
      "Current batch in main thread: 440000\n",
      "Current batch in main thread: 470000\n",
      "Current batch in main thread: 500000\n",
      "Current batch in main thread: 530000\n",
      "Current batch in main thread: 560000\n",
      "Current batch in main thread: 590000\n",
      "Current batch in main thread: 620000\n",
      "Current batch in main thread: 650000\n",
      "Current batch in main thread: 680000\n",
      "Current batch in main thread: 710000\n",
      "Current batch in main thread: 740000\n",
      "Current batch in main thread: 770000\n",
      "Current batch in main thread: 800000\n",
      "Current batch in main thread: 830000\n",
      "Current batch in main thread: 860000\n",
      "Current batch in main thread: 890000\n",
      "Current batch in main thread: 920000\n",
      "Current batch in main thread: 950000\n",
      "Current batch in main thread: 980000\n",
      "Current batch in main thread: 1010000\n",
      "Current batch in main thread: 1040000\n",
      "Current batch in main thread: 1070000\n",
      "Current batch in main thread: 1100000\n",
      "Current batch in main thread: 1130000\n",
      "Current batch in main thread: 1160000\n",
      "Current batch in main thread: 1190000\n",
      "Current batch in main thread: 1220000\n",
      "Current batch in main thread: 1250000\n",
      "Current batch in main thread: 1280000\n",
      "Current batch in main thread: 1310000\n",
      "Current batch in main thread: 1340000\n",
      "Current batch in main thread: 1370000\n",
      "Current batch in main thread: 1400000\n",
      "Current batch in main thread: 1430000\n",
      "Current batch in main thread: 1460000\n",
      "Current batch in main thread: 1490000\n",
      "Current batch in main thread: 1520000\n",
      "Current batch in main thread: 1550000\n",
      "Current batch in main thread: 1580000\n",
      "Current batch in main thread: 1610000\n",
      "Current batch in main thread: 1640000\n",
      "Current batch in main thread: 1670000\n",
      "Current batch in main thread: 1700000\n",
      "Current batch in main thread: 1730000\n",
      "Current batch in main thread: 1760000\n",
      "Current batch in main thread: 1790000\n",
      "Current batch in main thread: 1820000\n",
      "Current batch in main thread: 1850000\n",
      "Current batch in main thread: 1880000\n",
      "Current batch in main thread: 1910000\n",
      "Current batch in main thread: 1940000\n",
      "Current batch in main thread: 1970000\n",
      "Current batch in main thread: 2000000\n",
      "Current batch in main thread: 2030000\n",
      "Current batch in main thread: 2060000\n",
      "Current batch in main thread: 2090000\n",
      "Current batch in main thread: 2120000\n",
      "Current batch in main thread: 2150000\n",
      "Current batch in main thread: 2180000\n",
      "Current batch in main thread: 2210000\n",
      "Current batch in main thread: 2240000\n",
      "Current batch in main thread: 2270000\n",
      "Current batch in main thread: 2300000\n",
      "Current batch in main thread: 2330000\n",
      "Current batch in main thread: 2360000\n",
      "Finished computing heuristic features after 1147.83706212 seconds.\n",
      "Current all-time max memory: 6660 MB\n",
      "CPU times: user 9.26 s, sys: 1.3 s, total: 10.6 s\n",
      "Wall time: 19min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = parallel_get_features(test_df, is_train=False)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/canopy/lib/python2.7/site-packages/tables/path.py:112: NaturalNameWarning: object name is not a valid Python identifier: 'test-features-X_test'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 200 ms, total: 376 ms\n",
      "Wall time: 784 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test.to_hdf('kaggle-quora', 'test-features-X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_id = test_df.test_id\n",
    "\n",
    "# del(test_df)\n",
    "# del(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.065448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.161394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.213189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.043126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.037919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.065448\n",
       "1        1      0.161394\n",
       "2        2      0.213189\n",
       "3        3      0.043126\n",
       "4        4      0.037919"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "lm_sub = pd.DataFrame()\n",
    "\n",
    "lm_sub['test_id'] = test_id\n",
    "lm_sub['is_duplicate'] = lm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lm_sub.to_csv('lm_submission.csv', index=False)\n",
    "lm_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.365262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.149548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.173174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.048285\n",
       "1        1      0.365262\n",
       "2        2      0.149548\n",
       "3        3      0.005025\n",
       "4        4      0.173174"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "rf_sub = pd.DataFrame()\n",
    "\n",
    "rf_sub['test_id'] = test_id\n",
    "rf_sub['is_duplicate'] = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_sub.to_csv('rf_submission.csv', index=False)\n",
    "rf_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n",
    "scores_data = []\n",
    "samp = train_df\n",
    "\n",
    "for row in samp.iterrows():\n",
    "    if row[0] % 5000 == 0:\n",
    "        print(row[0])\n",
    "\n",
    "    scores_data.append(score_row(row))\n",
    "\n",
    "X = pd.DataFrame(scores_data)\n",
    "is_duplicate_test = np.mean(predict(X), axis=0)\n",
    "\n",
    "log_max_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
