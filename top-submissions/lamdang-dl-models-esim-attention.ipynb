{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/quora-question-pairs/discussion/34355\n",
    "# https://www.kaggle.com/lamdang/dl-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import *\n",
    "from keras.activations import softmax\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "MAX_LEN = 30\n",
    "\n",
    "\n",
    "def create_pretrained_embedding(pretrained_weights_path, trainable=False, **kwargs):\n",
    "    \"Create embedding layer from a pretrained weights array\"\n",
    "    pretrained_weights = np.load(pretrained_weights_path)\n",
    "    in_dim, out_dim = pretrained_weights.shape\n",
    "    embedding = Embedding(in_dim, out_dim, weights=[pretrained_weights], trainable=False, **kwargs)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def unchanged_shape(input_shape):\n",
    "    \"Function for Lambda layer\"\n",
    "    return input_shape\n",
    "\n",
    "\n",
    "def substract(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    neg_input_2 = Lambda(lambda x: -x, output_shape=unchanged_shape)(input_2)\n",
    "    out_ = Add()([input_1, neg_input_2])\n",
    "    return out_\n",
    "\n",
    "\n",
    "def submult(input_1, input_2):\n",
    "    \"Get multiplication and subtraction then concatenate results\"\n",
    "    mult = Multiply()([input_1, input_2])\n",
    "    sub = substract(input_1, input_2)\n",
    "    out_= Concatenate()([sub, mult])\n",
    "    return out_\n",
    "\n",
    "\n",
    "def apply_multiple(input_, layers):\n",
    "    \"Apply layers to input then concatenate result\"\n",
    "    if not len(layers) > 1:\n",
    "        raise ValueError('Layers list should contain more than 1 layer')\n",
    "    else:\n",
    "        agg_ = []\n",
    "        for layer in layers:\n",
    "            agg_.append(layer(input_))\n",
    "        out_ = Concatenate()(agg_)\n",
    "    return out_\n",
    "\n",
    "\n",
    "def time_distributed(input_, layers):\n",
    "    \"Apply a list of layers in TimeDistributed mode\"\n",
    "    out_ = []\n",
    "    node_ = input_\n",
    "    for layer_ in layers:\n",
    "        node_ = TimeDistributed(layer_)(node_)\n",
    "    out_ = node_\n",
    "    return out_\n",
    "\n",
    "\n",
    "def soft_attention_alignment(input_1, input_2):\n",
    "    \"Align text representation with neural soft attention\"\n",
    "    attention = Dot(axes=-1)([input_1, input_2])\n",
    "    w_att_1 = Lambda(lambda x: softmax(x, axis=1),\n",
    "                     output_shape=unchanged_shape)(attention)\n",
    "    w_att_2 = Permute((2,1))(Lambda(lambda x: softmax(x, axis=2),\n",
    "                             output_shape=unchanged_shape)(attention))\n",
    "    in1_aligned = Dot(axes=1)([w_att_1, input_1])\n",
    "    in2_aligned = Dot(axes=1)([w_att_2, input_2])\n",
    "    return in1_aligned, in2_aligned\n",
    "\n",
    "\n",
    "def decomposable_attention(pretrained_embedding='../data/fasttext_matrix.npy', \n",
    "                           projection_dim=300, projection_hidden=0, projection_dropout=0.2,\n",
    "                           compare_dim=500, compare_dropout=0.2,\n",
    "                           dense_dim=300, dense_dropout=0.2,\n",
    "                           lr=1e-3, activation='elu', maxlen=MAX_LEN):\n",
    "    # Based on: https://arxiv.org/abs/1606.01933\n",
    "    \n",
    "    q1 = Input(name='q1',shape=(maxlen,))\n",
    "    q2 = Input(name='q2',shape=(maxlen,))\n",
    "    \n",
    "    # Embedding\n",
    "    embedding = create_pretrained_embedding(pretrained_embedding, \n",
    "                                            mask_zero=False)\n",
    "    q1_embed = embedding(q1)\n",
    "    q2_embed = embedding(q2)\n",
    "    \n",
    "    # Projection\n",
    "    projection_layers = []\n",
    "    if projection_hidden > 0:\n",
    "        projection_layers.extend([\n",
    "                Dense(projection_hidden, activation=activation),\n",
    "                Dropout(rate=projection_dropout),\n",
    "            ])\n",
    "    projection_layers.extend([\n",
    "            Dense(projection_dim, activation=None),\n",
    "            Dropout(rate=projection_dropout),\n",
    "        ])\n",
    "    q1_encoded = time_distributed(q1_embed, projection_layers)\n",
    "    q2_encoded = time_distributed(q2_embed, projection_layers)\n",
    "    \n",
    "    # Attention\n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)    \n",
    "    \n",
    "    # Compare\n",
    "    q1_combined = Concatenate()([q1_encoded, q2_aligned, submult(q1_encoded, q2_aligned)])\n",
    "    q2_combined = Concatenate()([q2_encoded, q1_aligned, submult(q2_encoded, q1_aligned)]) \n",
    "    compare_layers = [\n",
    "        Dense(compare_dim, activation=activation),\n",
    "        Dropout(compare_dropout),\n",
    "        Dense(compare_dim, activation=activation),\n",
    "        Dropout(compare_dropout),\n",
    "    ]\n",
    "    q1_compare = time_distributed(q1_combined, compare_layers)\n",
    "    q2_compare = time_distributed(q2_combined, compare_layers)\n",
    "    \n",
    "    # Aggregate\n",
    "    q1_rep = apply_multiple(q1_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    \n",
    "    # Classifier\n",
    "    merged = Concatenate()([q1_rep, q2_rep])\n",
    "    dense = BatchNormalization()(merged)\n",
    "    dense = Dense(dense_dim, activation=activation)(dense)\n",
    "    dense = Dropout(dense_dropout)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(dense_dim, activation=activation)(dense)\n",
    "    dense = Dropout(dense_dropout)(dense)\n",
    "    out_ = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', \n",
    "                  metrics=['binary_crossentropy','accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def esim(pretrained_embedding='../data/fasttext_matrix.npy', \n",
    "         maxlen=MAX_LEN, \n",
    "         lstm_dim=300, \n",
    "         dense_dim=300, \n",
    "         dense_dropout=0.5):\n",
    "             \n",
    "    # Based on arXiv:1609.06038\n",
    "    q1 = Input(name='q1',shape=(maxlen,))\n",
    "    q2 = Input(name='q2',shape=(maxlen,))\n",
    "    \n",
    "    # Embedding\n",
    "    embedding = create_pretrained_embedding(pretrained_embedding, mask_zero=False)\n",
    "    bn = BatchNormalization(axis=2)\n",
    "    q1_embed = bn(embedding(q1))\n",
    "    q2_embed = bn(embedding(q2))\n",
    "    q1_embed = embedding(q1)\n",
    "    q2_embed = embedding(q2)\n",
    "    \n",
    "    # Encode\n",
    "    encode = Bidirectional(LSTM(lstm_dim, return_sequences=True))\n",
    "    q1_encoded = encode(q1_embed)\n",
    "    q2_encoded = encode(q2_embed)\n",
    "    \n",
    "    # Attention\n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)\n",
    "    \n",
    "    # Compose\n",
    "    q1_combined = Concatenate()([q1_encoded, q2_aligned, submult(q1_encoded, q2_aligned)])\n",
    "    q2_combined = Concatenate()([q2_encoded, q1_aligned, submult(q2_encoded, q1_aligned)]) \n",
    "       \n",
    "    compose = Bidirectional(LSTM(lstm_dim, return_sequences=True))\n",
    "    q1_compare = compose(q1_combined)\n",
    "    q2_compare = compose(q2_combined)\n",
    "    \n",
    "    # Aggregate\n",
    "    q1_rep = apply_multiple(q1_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    \n",
    "    # Classifier\n",
    "    merged = Concatenate()([q1_rep, q2_rep])\n",
    "    \n",
    "    dense = BatchNormalization()(merged)\n",
    "    dense = Dense(dense_dim, activation='elu')(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(dense_dropout)(dense)\n",
    "    dense = Dense(dense_dim, activation='elu')(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(dense_dropout)(dense)\n",
    "    out_ = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=['binary_crossentropy','accuracy'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
